{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import keras.backend as K\n",
    "from generator import DataGenerator\n",
    "PROJECT_NAME = \"LPRnet_keras\"\n",
    "MODEL_NAME = \"depthwise_model_randomchars_perspective_tflite\"\n",
    "\n",
    "IMAGE_SHAPE = [94,24]\n",
    "CHARS = \"ABCDEFGHIJKLMNPQRSTUVWXYZ0123456789\" # exclude I, O\n",
    "CHARS_DICT = {char:i for i, char in enumerate(CHARS)}\n",
    "DECODE_DICT = {i:char for i, char in enumerate(CHARS)}\n",
    "NUM_CLASS = len(CHARS)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    # Compute the training-time loss value\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class small_basic_block(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,out_channels,name=None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        out_div4=int(out_channels/4)\n",
    "        self.main_layers = [\n",
    "            keras.layers.SeparableConv2D(out_div4,(1,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_div4,(3,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_div4,(1,3),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_channels,(1,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "        ]  \n",
    "    \n",
    "    def call(self,input):\n",
    "        x = input\n",
    "        for layer in self.main_layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test this later\n",
    "\n",
    "class global_context(keras.layers.Layer):\n",
    "    def __init__(self,kernel_size,stride,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ksize = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def call(self, input):\n",
    "        x = input \n",
    "        avg_pool = keras.layers.AveragePooling2D(pool_size=self.ksize,strides=self.stride,padding='same')(x)\n",
    "        sq = keras.layers.Lambda(lambda x: tf.math.square(x))(avg_pool)\n",
    "        sqm = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x))(sq)\n",
    "        out = keras.layers.Lambda(lambda x: tf.math.divide(x[0], x[1]))([avg_pool , sqm])\n",
    "        #out = keras.layers.Lambda(lambda x: K.l2_normalize(x,axis=1))(avg_pool)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"kernel_size\": self.ksize,\n",
    "            \"stride\": self.stride,\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LPRnet(keras.Model):\n",
    "    def __init__(self, input_shape=(24,94,3), **kwargs):\n",
    "        super(LPRnet, self).__init__(**kwargs)\n",
    "        self.input_layer = keras.layers.Input(input_shape)\n",
    "        self.cnn_layers= [\n",
    "            keras.layers.SeparableConv2D(64,kernel_size = (3,3),strides=1,padding='same',name='main_conv1',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(name='BN1'),\n",
    "            keras.layers.ReLU(name='RELU1'),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,1),name='maxpool2d_1',padding='same'),\n",
    "            small_basic_block(128),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,2),name='maxpool2d_2',padding='same'),\n",
    "            small_basic_block(256),\n",
    "            small_basic_block(256),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,2),name='maxpool2d_3',padding='same'),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.SeparableConv2D(256,(4,1),strides=1,padding='same',name='main_conv2',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.SeparableConv2D(NUM_CLASS,(1,13),padding='same',name='main_conv3',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),  \n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "        ]\n",
    "        self.out_layers = [\n",
    "            keras.layers.SeparableConv2D(NUM_CLASS,kernel_size=(1,1),strides=(1,1),padding='same',name='conv_out',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "        ]\n",
    "        self.out = self.call(self.input_layer)\n",
    "\n",
    "    def call(self,inputs,training=False):\n",
    "        x = inputs\n",
    "        layer_outputs = []\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "            layer_outputs.append(x)\n",
    "        scale1 = global_context((1,4),(1,4))(layer_outputs[0])\n",
    "        scale2 = global_context((1,4),(1,4))(layer_outputs[4])\n",
    "        scale3 = global_context((1,2),(1,2))(layer_outputs[6])\n",
    "        scale5 = global_context((1,2),(1,2))(layer_outputs[7])\n",
    "        sq = keras.layers.Lambda(lambda x: tf.math.square(x))(x)\n",
    "        sqm = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x))(sq)\n",
    "        scale4 = keras.layers.Lambda(lambda x: tf.math.divide(x[0], x[1]))([x , sqm])\n",
    "        gc_concat = keras.layers.Lambda(lambda x: tf.concat([x[0], x[1], x[2], x[3], x[4]],3))([scale1, scale2, scale3, scale5,scale4])\n",
    "        for layer in self.out_layers:\n",
    "            gc_concat = layer(gc_concat)\n",
    "        logits = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x[0],axis=1))([gc_concat])\n",
    "        logits = keras.layers.Softmax()(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_1740/2036217571.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training_labels = np.array(labels)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "\n",
    "real_images_val = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\valid\\\\*\\\\*.png')\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\marty\\\\*\\\\*.png')\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "val_data = []\n",
    "val_labels = []\n",
    "\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    label = label.replace(\"O\",\"0\")\n",
    "    image = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image,(94,24))/256\n",
    "    data.append(image)\n",
    "    labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "\n",
    "for file in real_images_val:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    label = label.replace(\"O\",\"0\")\n",
    "    image = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image,(94,24))\n",
    "    val_data.append(image)\n",
    "    val_labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "\n",
    "training_set = np.array(data,dtype=np.float32)\n",
    "training_labels = np.array(labels)\n",
    "ragged = tf.ragged.constant(training_labels).to_tensor()\n",
    "real_dataset = tf.data.Dataset.from_tensor_slices((training_set,ragged)).batch(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(MODEL_NAME):\n",
    "    model = keras.models.load_model(\n",
    "        MODEL_NAME, custom_objects={\"global_context\": global_context, \"CTCLoss\": CTCLoss  }\n",
    "    )\n",
    "else:\n",
    "    model = LPRnet()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),loss =CTCLoss)\n",
    "    model.build((1,24,94,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_1740/2355684483.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training_labels = np.array(gen_labels)\n"
     ]
    }
   ],
   "source": [
    "from gen_plates_keras import *\n",
    "gen = ImageGenerator()\n",
    "def generate_dataset(num = 100):\n",
    "    data, labels = gen.generate_images(num)\n",
    "    gen_labels = []\n",
    "    for label in labels:\n",
    "        gen_labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "    pics =np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    training_set = np.array(pics,dtype=np.float32)\n",
    "    training_labels = np.array(gen_labels)\n",
    "    ragged = tf.ragged.constant(training_labels).to_tensor()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((training_set,ragged)).shuffle(640).batch(64)\n",
    "    return dataset\n",
    "test_dataset = generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mclsandoval\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/clsandoval/depthwise_model_randomchars_perspective_tflite/runs/2qdb4b96\" target=\"_blank\">expert-moon-4</a></strong> to <a href=\"https://wandb.ai/clsandoval/depthwise_model_randomchars_perspective_tflite\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=MODEL_NAME, entity=\"clsandoval\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 400,\n",
    "  \"batch_size\": 64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = DataGenerator()\n",
    "check = tf.keras.callbacks.ModelCheckpoint(\n",
    "    './trained_models/{}'.format(MODEL_NAME),\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=500,\n",
    "    options=None,\n",
    ")\n",
    "model.fit(test_dataset)\n",
    "model.fit_generator(generator=generate,validation_data=real_dataset,validation_steps=3,epochs=11,steps_per_epoch=50,callbacks=[WandbCallback(),check])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TFLITE_PATH = 'tflite_models'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"./{}/{}.tflite\".format(TFLITE_PATH,MODEL_NAME), 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(\"C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\tflite_models\\\\depthwise_model_randomchars_perspective_tflite.tflite\")\n",
    "#interpreter = tf.lite.Interpreter(\"C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\tflite_models\\\\keras_lprnet_separable.tflite\")\n",
    "import numpy as np\n",
    "import time \n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\marty\\\\*\\\\*.png')\n",
    "start = time.time()\n",
    "ctr = 0\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    image = cv2.imread(file)\n",
    "    test_image = cv2.resize(image,(94,24))/256\n",
    "    test_image = np.expand_dims(test_image,axis=0)\n",
    "    test_image = test_image.astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    decoded = keras.backend.ctc_decode(output_data,(24,),greedy=False)\n",
    "    text = \"\"\n",
    "    for i in np.array(decoded[0]).reshape(24):\n",
    "        if i >-1:\n",
    "            text += DECODE_DICT[i]\n",
    "    if label == text:\n",
    "        ctr += 1\n",
    "    print(text, \" \"+ label)\n",
    "print(time.time()-start)\n",
    "print(ctr,len(real_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'trained_models'\n",
    "TFLITE_PATH = 'tflite_models'\n",
    "model = keras.models.load_model(\n",
    "    os.path.join(MODEL_PATH, MODEL_NAME), custom_objects={\"global_context\": global_context, \"CTCLoss\": CTCLoss  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86ZSCLAA  07303\n",
      "71DE38SEBAE5A  1303\n",
      "13008A2  1303\n",
      "566TPEAA  566TPE\n",
      "E5TQA  57\n",
      "5E500TGAAA  59\n",
      "AQ35TJAA  AA03573\n",
      "AAK7063AA  AAK7053\n",
      "AAEZ4G73A  AAL4673\n",
      "ATG3T7TFA  ACG3105\n",
      "AD35293AA  AD35293\n",
      "DAL5017AA  DAL5017\n",
      "DAMX900A  DAM7900\n",
      "DC8T27  DC18721\n",
      "6ZGTE5AA  G2G725\n",
      "NAF6171  NAF6171\n",
      "NBK7446  NBK7446\n",
      "MG5TE5ZAAA  NC57254\n",
      "NCG1092Z  NCG1092\n",
      "NCZ5306  NCZ5306\n",
      "EE3253FAA  NDB3253\n",
      "NET0G3GAA  NE70636\n",
      "NET0G3GAA  NE84727\n",
      "NEJ990D0A  NEJ9900\n",
      "N6E2785AA  NH\n",
      "PTY5UTAA  PYV501\n",
      "VJNXTLBAAA  TJX496\n",
      "V50AT54AAA  WSO154\n",
      "ZUVZ5TAA  ZJV257\n",
      "E305PFG5AA  1303\n",
      "943N0XAA  943NOX\n",
      "UDAE3011AA  DAE3011\n",
      "NAH7401A  NAH7401\n",
      "M8G1384A  NBG1384\n",
      "NBV2323  NBV2323\n",
      "NC16514A  NCI6514\n",
      "NCJ9396  NCJ9396\n",
      "NCU3758A  NCU3758\n",
      "ND11397  NDI1397\n",
      "3ZT51EDAAA  NDT5180\n",
      "NDU6721AA  NDU6721\n",
      "ENET179AA  NET1793\n",
      "NGG6277AA  NGG6277\n",
      "TTA8KQJTAA  TYX907\n",
      "0GEB09AA  UGF809\n",
      "BET339AA  WET339\n",
      "EF19E0FAAA  XSC203\n",
      "YSB054  YS6054\n",
      "AAH70G2A  AAH7062\n",
      "AAZ2G55A  AAZ2655\n",
      "DBG5953A  ABG5953\n",
      "ACZED0AA  ACZ4349\n",
      "1P1BTT5A  APA8716\n",
      "NAD1140  NAD1140\n",
      "NLV727UJA  NBQ2703\n",
      "NETE34ZA  NCY8340\n",
      "NDG3354  NDG3354\n",
      "UTTAB46AA  UIT846\n",
      "DVC54E5AAA  UVC646\n",
      "UHK573AA  UWK673\n",
      "TX5JTE2  XSJ122\n",
      "LEB76BAA  ZBT716\n",
      "ZRJ695AAA  ZRJ695\n",
      "1303T057279D0A  1303\n",
      "AAN8827  AAN8821\n",
      "EA3VT2TQA  AAW1219\n",
      "AAW4G29AA  AAW4629\n",
      "ABE8429A  ABL8429\n",
      "AB0G833T  ABO6833\n",
      "AXA2G23A  AXA2623\n",
      "P464P2AAA  B1G115\n",
      "F85H59TEL2EAA  B5H597\n",
      "E88VHT3JAAA  B6V113\n",
      "CCN6359A  CCN6359\n",
      "DAH3990A  DAH3990\n",
      "DA14759A  DAI4759\n",
      "DAJ40865  DAJ4086\n",
      "DAK4Z21A  DAK4221\n",
      "LDAE485TAA  DAK4857\n",
      "0JXEBAAAA  DJX849\n",
      "NX4QMB35  DNS315\n",
      "DPY74TAA  DPV741\n",
      "EVTUFYAAA  DSV307\n",
      "NAK7704A  NAK7704\n",
      "EA07760A  NAO7760\n",
      "NBG5119  NBG5119\n",
      "ND11475  NDI1475\n",
      "NEA4707A  NEA4707\n",
      "NED9729AA  NED9729\n",
      "PPT88EAA  P1P786\n",
      "PNMB50A  PNM850\n",
      "TTET52AA  TIE152\n",
      "T06856AA  TO6856\n",
      "0BG628AAA  UBG628\n",
      "UE1G9AA  UER469\n",
      "0D0ZAT63AA  UQZ163\n",
      "NM2JAT7TAAA  VFN171\n",
      "JHV3EAAA  WGV361\n",
      "WGY544A  WGV544\n",
      "WEB333AA  WLB333\n",
      "LUEF8UAAA  WOC930\n",
      "QTTX34AA  WTT334\n",
      "CTETD88  XFT404\n",
      "XXU282AAA  XKU282\n",
      "ETE0TAA  XRV697\n",
      "Z0ZE448  ZGZ449\n",
      "0A9484757  0414\n",
      "GE051PDA  2061HQ\n",
      "Z3152AAA  7131523\n",
      "AAA5G24A  AAA5624\n",
      "ADHBTE5  AAH9765\n",
      "AAP3BT7A  AAP3811\n",
      "AAYSS43AA  AAV9943\n",
      "ABD3G87AA  ABD3687\n",
      "ABD382AA  ABD8382\n",
      "ABEGG47A  ABE6647\n",
      "E8DH4224AAA  ABH4224\n",
      "DB555TAA  ABS1591\n",
      "ZDBT208SA  ABT2089\n",
      "EE155T3A  ACA5513\n",
      "ACAS505AAA  ACA9509\n",
      "EC147Y0A  ACB4710\n",
      "UF1S6EZAA  AFA9422\n",
      "UAR12Z4TJA  ARA2473\n",
      "50A735AA  AUA7369\n",
      "B3DERJDB7AAA  CAC9414\n",
      "EUEU5A  CNB956\n",
      "DX3GT37  DA36137\n",
      "EEA3281AA  DAA3281\n",
      "DAA6079A  DAA6079\n",
      "DA790Z  DAA7902\n",
      "DAB31J7AA  DAB3117\n",
      "DAB9203  DAB9203\n",
      "DAF3151  DAF3151\n",
      "DAE69J2AA  DAI6912\n",
      "VDAJ1537  DAJ3537\n",
      "DAJ6Z37AA  DAJ6287\n",
      "DAM4661YA  DAM4661\n",
      "DAN6674AA  DAN6674\n",
      "DAN9661  DAN966I\n",
      "DA08297A  DAO8297\n",
      "DCSD5T85AA  DC98919\n",
      "DCQ5208Y  DCQ5208\n",
      "0TTT09YA  DTJ189\n",
      "DYZ252AA  DVZ253\n",
      "E2EAAA  E2K336\n",
      "FTYG43EAAA  F11643\n",
      "FJE6TAAA  FJF161\n",
      "EUAC5057W  IAC5057\n",
      "EK5750A  K1S750\n",
      "NAA8802A  NAA8602\n",
      "NA1G78MQAA  NAD7889\n",
      "NAGB532AA  NAG8632\n",
      "NZH517DAA  NAH5170\n",
      "NAK7472  NAK7472\n",
      "WALB4B2  NAL8482\n",
      "NAQ368DA  NAQ3680\n",
      "NAQ4851A  NAQ4851\n",
      "NAW6798  NAW6798\n",
      "NAZ3097A  NAZ3097\n",
      "N8C3031AA  NBC3031\n",
      "BH1332A  NBH1332\n",
      "Y8Q1076A  NBQ1076\n",
      "ZBR9005  NBR9005\n",
      "NBR9005  NBR9005\n",
      "NCC5J53  NCC5153\n",
      "NCK8809  NCK8809\n",
      "NCN4242A  NCN4242\n",
      "NE0455JTA  NCO4558\n",
      "NCY70ZA3A  NCY7023\n",
      "NDD3762A  NDD3762\n",
      "UEETEAAA  NDH384\n",
      "NDK0919A  NDK4919\n",
      "NCE1031AA  NDL1031\n",
      "NEA5358  NEA5358\n",
      "UNGF6077A  NGF6077\n",
      "NGJ9244A  NGJ9244\n",
      "RVTEDEAA  NII609\n",
      "EDKBAAA  NK6884\n",
      "NVUXBUEAA  NVQ802\n",
      "P6A8JSAAA  P6A833\n",
      "PTZAF56TAAA  PIL567\n",
      "EP00337A  POO331\n",
      "PQP335TAA  POP935\n",
      "EP121TA  PPJ937\n",
      "PDP835AA  PQP935\n",
      "EUU9V9AA  TOQ799\n",
      "TPWTZJAA  TRW123\n",
      "TTTCBH5AA  TTC866\n",
      "CMUZET48  U2L148\n",
      "UTPN5ZAA  UIF452\n",
      "0D5TDAAA  UIO570\n",
      "EUKEAH8AA  UKE484\n",
      "DXG15PAAA  UKG469\n",
      "EUEU7RZ0AAA  ULQ724\n",
      "EUWTAT66HA  UMI168\n",
      "883RU5AAA  UOE405\n",
      "UAEZ00AAA  UTY200\n",
      "EAAA  VFG420\n",
      "TVFG1Z0AAA  VFG420\n",
      "LMYA3GZAA  VFN382\n",
      "E8EN2TBAA  WDN218\n",
      "DVJ04Z8ZA  WJO282\n",
      "XBEYEAAA  XBN872\n",
      "SXBE3G0AAA  XGE460\n",
      "EXKD232AAA  XKD232\n",
      "VVEUAAA  XMV847\n",
      "XY1XNP6UAAA  XPX984\n",
      "EEZ758ZEAAA  YZ7587\n",
      "E0NEEYAAA  ZGH827\n",
      "ZG5A365AAA  ZHA385\n",
      "EGAAA  ZKN158\n",
      "7UBTJAAA  ZSJ373\n",
      "010103AA  010103\n",
      "E6FDTJ58AAA  0301\n",
      "JU5J1TJJZJ  04011290399\n",
      "MQ5D204SG5  13030204653\n",
      "136605AA  136605\n",
      "290C1QA  29OCIQ\n",
      "E9ZEZPAAA  4940SR\n",
      "A2J023A  A2J023\n",
      "A3JA07AA  A3J401\n",
      "A3QQ4TAAA  A3O047\n",
      "A5L0TD  A5L070\n",
      "AAA5GSB  AAA6698\n",
      "AAB7T55  AAB7156\n",
      "E8TE6U2AA  AAI8602\n",
      "A1YB244  AAY8244\n",
      "VEAY5424  AAY9424\n",
      "ABDG53AA  ABD6531\n",
      "EABDG537  ABD6531\n",
      "ABG20B0A  ABG2080\n",
      "ABG7G83A  ABG7683\n",
      "ABHS238AA  ABH9238\n",
      "ABQ7SG5A  ABO1365\n",
      "AB07280  ABO7280\n",
      "AB0TDA5A  ABQ1049\n",
      "AE0TDAA  ABU1049\n",
      "ACC9144  ACC9144\n",
      "ACD2587A  ACD2587\n",
      "AEK77DA  ACK7570\n",
      "AAA8GTBAA  AHA8618\n",
      "LEEXR855JAAA  AIR355\n",
      "AKA3077  AKA3077\n",
      "ARA5G77TA  ARA5677\n",
      "UATA8556G  ATA8556\n",
      "B4UTG9A  B4U769\n",
      "EAE169AAA  CAG1698\n",
      "ECAK6752  CAK6752\n",
      "CDJ2454  CDJ2454\n",
      "CNK56TXA  CNK561\n",
      "DAM7478  DAM7478\n",
      "TDCP1383  DCP1383\n",
      "TAC1809  IAC1809\n",
      "KT0255A  K1Q255\n",
      "NA18468A  NAI8468\n",
      "NAK4217  NAK4217\n",
      "NAP9900A  NAP9900\n",
      "PAV6098A  NAV0698\n",
      "9BG6EZ90AA  NBG6290\n",
      "N8T36ZUAA  NBT8620\n",
      "NBY4971  NBY4971\n",
      "NBZ3785A  NBZ3785\n",
      "GSD3TEA  NCG2307\n",
      "NCM8560  NCM8560\n",
      "LNCQ1872A  NCQ1872\n",
      "ND202GSAA  ND2069\n",
      "NDA3544A  NDA3544\n",
      "NDG3903  NDG3903\n",
      "NDN7293E  NDN7293\n",
      "NDP6220  NDP6220\n",
      "DDE70AA  NDZ1056\n",
      "NE5JD3A  NE59313\n",
      "NEH7107A  NEH7107\n",
      "BNEX7Z4ZA  NEX7747\n",
      "TNGL1528  NGL1528\n",
      "UUA39JAAA  NOO399\n",
      "NR90G8A  NR9068\n",
      "9P1FGATA  P1F641\n",
      "EP7F693AA  P7F693\n",
      "PV0AEEZAAA  PMO952\n",
      "PDEEEGAAA  POE223\n",
      "FFWFS8BAAA  RMP968\n",
      "5WSETAAA  SHS873\n",
      "TAZSB54A  TAZ864\n",
      "TLU333  TLU333\n",
      "EESB20AA  TYS820\n",
      "ETY4T2AA  TYV412\n",
      "ELZE5AAA  TYZ746\n",
      "UJB4BAA  UJI849\n",
      "0HF505AAA  UWF505\n",
      "0YA95BA  UYA998\n",
      "HUTZBT5AA  WQT879\n",
      "XCC295AA  XCC295\n",
      "RE7XE5EEAA  YX5656\n",
      "EZYEBT0AAA  ZHE810\n",
      "XHX1756A  ZHX756\n",
      "EVJWV955AA  ZJN955\n",
      "ZJWA955AA  ZJW955\n",
      "Q4011Q1200B  0401\n",
      "E13030BA103  1303\n",
      "T503D8B5B  1303\n",
      "EZ6E8XYAA  2629XY\n",
      "T532NEAA  7532NE\n",
      "EA0N0G8A  A0N068\n",
      "AAA75G7  AAA7567\n",
      "AAC95G9  AAC9569\n",
      "AAKG508SA  AAK6509\n",
      "EA09380A  AAO9380\n",
      "EXPE3JS  AAP6303\n",
      "AAX2GG3A  AAX2663\n",
      "B5Z36A  AAY5204\n",
      "AAZ2B30AA  AAZ2830\n",
      "ABC17355A  ABC7355\n",
      "LABD45T2A  ABD4512\n",
      "ABG70G7TAA  ABG7067\n",
      "ABT955  ABI9699\n",
      "AB0G025A  ABO6025\n",
      "UDTT078  ABT7078\n",
      "WCEBSSA4AAA  ACC8554\n",
      "DA4057TAAA  ADA4057\n",
      "UAEA8T64  AEA8194\n",
      "AFA5159  AHA5169\n",
      "UKAS8GSA  AKA9869\n",
      "NBK8135  ANBK8135\n",
      "EA0A5535AA  AOA5935\n",
      "EA0A7S85V  AOA7985\n",
      "ARA3323A  ARA3323\n",
      "XS35545A  ASA5948\n",
      "ES1S283A  ASA9283\n",
      "3Y32BZ4AA  AVA2844\n",
      "APA3740A  AVA3740\n",
      "QG9ST32AA  C1T903\n",
      "CA0669TAA  CAO6691\n",
      "CUP7941A  CAP7941\n",
      "CAR4515  CAR4515\n",
      "CTG666A  CIG666\n",
      "JCJ59D0AA  CJ5900\n",
      "CJ590DA  CJS900\n",
      "DAD2961AA  DAD2961\n",
      "DAD3517  DAD3517\n",
      "DAF8862  DAF8862\n",
      "DAG8779A  DAG8779\n",
      "DA13387  DAI3387\n",
      "DAJ3840  DAJ3840\n",
      "DAJ8485A  DAJ8485\n",
      "DAL3958A  DAL3958\n",
      "DAL9511  DAL9511\n",
      "DAN2477  DAN2477\n",
      "DAZ125AEA  DAZ1254\n",
      "5DBZ563ZA  DBZ5632\n",
      "DD5057AA  DD50157\n",
      "DDL9971  DDL9971\n",
      "DGE350AAA  DGE350\n",
      "8DGJ185GA  DGJ186\n",
      "DTB574A  DTB574\n",
      "DVH590AA  DVH690\n",
      "BXTABAAA  DXT488\n",
      "DTW3E0AAA  DXW427\n",
      "DETAAA  DXW427\n",
      "AEEAZ6AAA  ECA26\n",
      "EZCB8BAA  EZC888\n",
      "EEHEEBAAA  FEH888\n",
      "FJUX330AA  FJD330\n",
      "FRK2G8A  FRK248\n",
      "GA8145AAA  GAO1457\n",
      "EGCG21ATA  GCG21\n",
      "ED6857A  GED6857\n",
      "DAC7876AA  IAC7876\n",
      "EJD01971A  JDO1971\n",
      "NV70202  NA7020\n",
      "NAB5970A  NAB5970\n",
      "NAB8378AA  NAB8378\n",
      "NAEE4CTAA  NAC5407\n",
      "NAE3124  NAE3124\n",
      "NAE3970AA  NAE3970\n",
      "NAK4228A  NAK4228\n",
      "HAL1727AA  NAL1727\n",
      "NAN9317  NAN9317\n",
      "AP8301A  NAP8301\n",
      "ENAQ6323T  NAQ6323\n",
      "H8V1S79AA  NAV1579\n",
      "NAV2808A  NAV2808\n",
      "AV28BB  NAV2888\n",
      "NAV3156  NAV3156\n",
      "NAY6252AA  NAY6252\n",
      "NAZ2072A  NAZ2072\n",
      "NAZ6492  NAZ6492\n",
      "N8F7744  NBF7744\n",
      "NBH6470AA  NBH6470\n",
      "N513451  NBI3452\n",
      "N8K8135  NBK8135\n",
      "NB03078AAA  NBO3076\n",
      "NBP4517  NBP4517\n",
      "NBP829DA  NBP8290\n",
      "NBQ3076  NBQ3076\n",
      "NBW2508AA  NBW250B\n",
      "NC855TBAA  NC85518\n",
      "NCC3638T  NCC3638\n",
      "NCF7371A  NCF7371\n",
      "NCJ2777A  NCJ2777\n",
      "NCJ5296  NCJ5296\n",
      "NCN7186  NCN7186\n",
      "C014447  NCO1444\n",
      "NC01652A  NCO1652\n",
      "NC01652P  NCO1652\n",
      "NC01981  NCO1981\n",
      "WC05754  NCO5754\n",
      "NCR5029AA  NCR5029\n",
      "CS2063AA  NCS2063\n",
      "NCU9931AA  NCU9931\n",
      "NCV1992A  NCV1992\n",
      "NDC5973  NDC5973\n",
      "NDM1741A  NDM1741\n",
      "NDN1237AA  NDN1237\n",
      "NDU2906  NDU2906\n",
      "NDU8361A  NDU8361\n",
      "NDU9234  NDU9234\n",
      "DV2062A  NDV2062\n",
      "NEA2431AA  NEA2431\n",
      "NEC6356  NEC6356\n",
      "NEJ8420  NEJ8420\n",
      "NEU6437A  NEU6437\n",
      "NFU5518  NFU5518\n",
      "NFW1871A  NFW1871\n",
      "NFY2649  NFY2649\n",
      "JNG81E199  NGB1199\n",
      "NGG4780A  NGG4780\n",
      "NGG7107A  NGG7107\n",
      "U0UE65AAA  NGO885\n",
      "VUEE7AAA  NHQ287\n",
      "NTXT23AA  NIX123\n",
      "EENE907TEA  NL9071\n",
      "NHT1594AA  NMI694\n",
      "N0KXT43A  NOK143\n",
      "AJUEEHAAA  NOO885\n",
      "N0X35TAAA  NOX351\n",
      "EYE85QA  NYE860\n",
      "ULUXYAAA  OGA77\n",
      "E0Y7ATT  OY1477\n",
      "EPSESZEA  P5E528\n",
      "EP5PBG3A  P5P863\n",
      "P8GG00EAA  P6G600\n",
      "9P6E7T41  P6L114\n",
      "NP80055AA  P8O055\n",
      "PEDX2JZAAA  PHO232\n",
      "PE0929AA  PLO929\n",
      "P0T547AAA  PQT541\n",
      "P0X80TAA  PQX901\n",
      "PUY5Z4AA  PQY624\n",
      "EHH3TDAA  PRW311\n",
      "BYE38EAA  PYL388\n",
      "PAK5250A  RAK925\n",
      "EEE2T9AA  RFE979\n",
      "EJB2Z5AAA  SJB215\n",
      "JUEZT5AAA  SJB215\n",
      "2TDAAA  TAI176\n",
      "TDT14F5AAA  TOI495\n",
      "UTUP547AA  TQP549\n",
      "TXT33TAAA  TXT437\n",
      "TYXKA5AA  TYK436\n",
      "DTF5G7AAA  UHR581\n",
      "AYEXG8TAA  UIL681\n",
      "1U1TAZ8T7AA  UIY247\n",
      "UKXASEAAA  UKX430\n",
      "DDTS5TDAAA  UOT570\n",
      "TUYB37TAAA  UVB371\n",
      "0VE53AEA  UVL934\n",
      "U0F88TA  UWF881\n",
      "0FJB67A  UWJ867\n",
      "UME02EZAA  WGD242\n",
      "UEEUUAAA  WII300\n",
      "WA56AA  WIJ569\n",
      "EWWE2GTAAA  WIK581\n",
      "GMJPT52AA  WJR152\n",
      "LW0X796AAA  WMO796\n",
      "HFYBV5AAA  WPN848\n",
      "X6GX5YAAA  XBC957\n",
      "TEX69G7A  XLX969\n",
      "EXGEEE3AA  XNC833\n",
      "TTE50TAA  XNL534\n",
      "X6F6E7AAA  XSP627\n",
      "EYUT945AA  YU7945\n",
      "DY237E8AAA  YZ3708\n",
      "ZTT4FEAAA  ZAN589\n",
      "ZDRB52A  ZDR859\n",
      "ZEZ953AAA  ZEL953\n",
      "EEDAGAAA  ZJA416\n",
      "ZPE19ZEAAA  ZMC926\n",
      "04280AA  042810\n",
      "EER57AAA  6X8467\n",
      "S7373QCAAA  7673QC\n",
      "998DRXA  998DKX\n",
      "UAE8475  AAC8475\n",
      "AAC8547  AAC9541\n",
      "EBE732SAA  ABE7329\n",
      "EABE7325AA  ABE7329\n",
      "AHA94G9  AHA9489\n",
      "VA5T04  AVA5704\n",
      "B6U485AAA  B6U485\n",
      "5BTA55TT  B7A597\n",
      "CA16024A  CAI6024\n",
      "DAA5756  DAA5756\n",
      "DAA6207AAA  DAA6207\n",
      "DAB6695  DAB6695\n",
      "DAC8346YA  DAC8346\n",
      "DZC9591A  DAC9591\n",
      "DAG9983  DAG9983\n",
      "DAK2002A  DAK2002\n",
      "DAK4631  DAK4631\n",
      "DAL1937A  DAL1937\n",
      "DAN2120A  DAN2120\n",
      "2292849A  DAN2849\n",
      "DAN4020  DAN4020\n",
      "DA05827  DAO5827\n",
      "DAT1647AA  DAT1647\n",
      "DAT7458AA  DAT7458\n",
      "DAZ9022  DAZ9022\n",
      "DBA5608  DBA5608\n",
      "DBA8632X  DBA8632\n",
      "DBZ8883  DBZ8883\n",
      "DCB3312  DCB3312\n",
      "DCQ2268A  DCQ2268\n",
      "DCQ376BAA  DCQ3740\n",
      "DCQ9890A  DCQ9890\n",
      "DDL46B6  DDL4686\n",
      "DDL546B  DDL5468\n",
      "DEB1684  DEB1684\n",
      "ED5CS04FAA  DSC904\n",
      "UDVV58BBAA  DVV688\n",
      "FT3T96E5AA  F3T408\n",
      "EG2W528EHA  G2W528\n",
      "MUUDRC6AAA  HOT88\n",
      "EJFBE4AA  JM8241\n",
      "NAF3554  NAF3554\n",
      "ZAAZ143AAA  NAH4143\n",
      "NAL9515  NAL9515\n",
      "NAX5446  NAX5446\n",
      "N8C6046A  NBC6046\n",
      "NBJ35AEA  NBJ355\n",
      "NBT786F  NBT7866\n",
      "NCA3963A  NCA3963\n",
      "NCB4238  NCB4238\n",
      "ENCGG4A  NCI664\n",
      "NCTGG4XA  NCI664\n",
      "YCJ8265  NCJ8265\n",
      "NCT8023AA  NCT8023\n",
      "NCU4340  NCU4340\n",
      "NDU1689AA  NDU1689\n",
      "G6697  NEA6697\n",
      "NEG4765  NEG4765\n",
      "NEH6898  NEH6898\n",
      "NET8936A  NEI8936\n",
      "NGF9950  NGF9950\n",
      "NGN2484  NGN2484\n",
      "EZEZZAAA  NRI622\n",
      "NUY353AA  NUI393\n",
      "EP9R0Q9AA  P9R001\n",
      "PT4BT7AAA  PPT487\n",
      "P0F874A  PQF874\n",
      "PHJ5ULAA  PRW350\n",
      "REEZE4A  REF224\n",
      "RGJ854AA  RGJ994\n",
      "F51F22QAGAA  S1F220\n",
      "E5H5T9AAA  SHS197\n",
      "JJZTAAA  SJD418\n",
      "SJY3TZAAA  SJV372\n",
      "TT0A300A  TIO300\n",
      "TEDF7T5AA  TLD719\n",
      "GTP0T75A  TMU175\n",
      "TQL32TA  TQL321\n",
      "TRU7G2AA  TRU762\n",
      "UEW335FA  UEM345\n",
      "LUEG669AAA  UGN669\n",
      "UHE795AA  UHE795\n",
      "EUUJ3Z3AA  UOS323\n",
      "UQE52AAA  USJ552\n",
      "YFA832A  VFA832\n",
      "V6VF0TAAA  VOY901\n",
      "WBQ30T  WBQ301\n",
      "EXU409AA  WKO409\n",
      "AHTA532AAA  WMI532\n",
      "WFNGY2AAA  WPN874\n",
      "XCZ22A  XCZ221\n",
      "XDEZG9AA  XDF269\n",
      "EXTGB3TA  XTG837\n",
      "YC28U2AAA  YC2412\n",
      "ZABT03A  ZAB103\n",
      "ZED8G3A  ZED963\n",
      "ZEA25GAA  ZEM256\n",
      "EHUZE0AA  ZHU220\n",
      "GZJWA33BAAA  ZJM338\n",
      "EFUZ5JAAA  ZPD628\n",
      "AAC158G  AAC1586\n",
      "A59DLYAA  459DLY\n",
      "YA105592  AAO5592\n",
      "APA3772A  APA3772\n",
      "DAA4626D  DAA4626\n",
      "DAF9190  DAF9190\n",
      "DAJ1083  DAJ1083\n",
      "DAL3300A  DAL3300\n",
      "DCP7079A  DCP7079\n",
      "ENBU4828  NBU4828\n",
      "NCG1221  NCG1221\n",
      "NCH8029A  NCH8029\n",
      "NCM9415  NCM9415\n",
      "NEH1B15  NEH1815\n",
      "NFX7563  NFX7563\n",
      "NGS2592  NGS2592\n",
      "AAJ5207A  AAJ5201\n",
      "AAP7274A  AAP1274\n",
      "AAUJ583A  AAW1583\n",
      "ABA8GT5A  ABA8615\n",
      "AEA8483A  AEA9483\n",
      "AE95T2AAA  AEA9512\n",
      "ARAGB28T  ARA6828\n",
      "JASA8G80  ASA8680\n",
      "SCAQ6650  CAQ6650\n",
      "CPY7T7AA  CPY711\n",
      "DAG3746A  DAG3746\n",
      "DAH3150  DAH3150\n",
      "DAK1304T  DAK1304\n",
      "DAL7407  DAL7407\n",
      "JDA06200E  DAO6200\n",
      "DAY1428AA  DAY1428\n",
      "DCP5431  DCP5431\n",
      "DCP7323  DCP7323\n",
      "NA3G503  NA36503\n",
      "NAE1322A  NAE1322\n",
      "NAE2008  NAE2008\n",
      "NAJ874DA  NAJ8740\n",
      "NBA4750AA  NBA4750\n",
      "NBK6857  NBK6857\n",
      "NBP3395  NBP3395\n",
      "NBR9407  NBR9407\n",
      "NC04583  NC04583\n",
      "NCD4761AA  NCD4761\n",
      "NCM8042  NCM8042\n",
      "NCM9147A  NCM9147\n",
      "NDE9713  NDE9713\n",
      "NDF2712  NDF2712\n",
      "NDJ3111  NDJ3111\n",
      "NDS1024  NDS1024\n",
      "NY1148  NDV1148\n",
      "NEA4294A  NEA4294\n",
      "NED230A  NED2300\n",
      "NED3275  NED3275\n",
      "NEH4482  NEH4482\n",
      "NGJ4631  NGJ4631\n",
      "T5H402TAA  TSN402\n",
      "153NDEA  153NDE\n",
      "ABR53T0A  ABR5310\n",
      "CAB1069  CAB1069\n",
      "NA02641  NA02641\n",
      "NBC2309  NBC2309\n",
      "EN8FB8676FA  NBF8676\n",
      "NDT7127  NDT7127\n",
      "NE2G2TGAA  NE26216\n",
      "UABE23T3AA  ABE2313\n",
      "A3HFSA4AA  ABH1544\n",
      "NB15456  NBI5456\n",
      "NBT2564  NBT2564\n",
      "NDT8216  NDT8216\n",
      "NEB8Z74  NEB8274\n",
      "NFT6109AA  NFT6109\n",
      "G3D1DJLAA  401DJL\n",
      "ADA58S2  ADA5892\n",
      "APA7080AA  APA7080\n",
      "CDZ5495  CDZ5495\n",
      "CDAL8625  DAL8625\n",
      "DRE923AAA  DRL923\n",
      "MJZT58AA  MJZ168\n",
      "NAT6342  NAT6342\n",
      "NCC7M00  NCC1100\n",
      "NDC2372  NDC2372\n",
      "EEA5561AA  NEA5661\n",
      "510TPDA  510TPD\n",
      "AAM4S0TA  AAM4901\n",
      "AAQ8870A  AAQ8870\n",
      "AXA3085  AXA3085\n",
      "DAA7239  DAA7239\n",
      "EDAG11957A  DAG1195\n",
      "NBE1565  NBE1565\n",
      "NCH2661  NCH2661\n",
      "NCT8802  NCT8802\n",
      "NGF4110  NGF4110\n",
      "NGS8307  NGS8307\n",
      "307PZAAA  307PZA\n",
      "BAC1219AA  BAC1219\n",
      "Z5LAAA  ZCV116\n",
      "A2Z021AA  A2Z021\n",
      "AAJSTBTA  AAJ9181\n",
      "EEW56AAA  CLM544\n",
      "3DAA9889  DAA9889\n",
      "CDAJ332AAA  DAJ3327\n",
      "DAT1060  DAT1060\n",
      "DET0TT9AA  DC70119\n",
      "GCS7606  GCS7606\n",
      "ANAE1815  NAE1815\n",
      "NAR3508E  NAR3508\n",
      "NAT1827  NAT1827\n",
      "NBA9743A  NBA9743\n",
      "NCR8656  NCR8656\n",
      "NDA1963A  NDA1693\n",
      "NEX7507  NEX7507\n",
      "NFY2439A  NFY2439\n",
      "ANFY2439  NFY2439\n",
      "TJP3G3A  TJP363\n",
      "TYR689A  TYR689\n",
      "ABH8858A  ABH8899\n",
      "ABQ7G59A  ABQ7659\n",
      "AB08G2GA  ABQ9626\n",
      "AKA9280  AKA9280\n",
      "DAH3342  DAH3342\n",
      "NAK4386A  NAK4386\n",
      "NCP1449  NCP1449\n",
      "3HT2AYAA  URT124\n",
      "EYT405AA  YT4054\n",
      "AAY4074  AAY4074\n",
      "ATA3251  AIA3251\n",
      "DAC3C13  DAC3413\n",
      "DAF4129A  DAF4129\n",
      "DAT9086  DAI9086\n",
      "UDAJ4126L  DAJ4126\n",
      "DCP9554E  DCP9554\n",
      "DYTJJJAA  DYT333\n",
      "NBA7993  NBA7993\n",
      "NBV6196  NBV6196\n",
      "NCW7897A  NCW7897\n",
      "AGA6883AA  AGA6883\n",
      "E1TSTTAAA  AKA3673\n",
      "DBA1734A  DBA1734\n",
      "SCP1485A  DCP1485\n",
      "EBE679QAAA  DDL6798\n",
      "NGY2496  NGY2496\n",
      "GN3TQ9HEAA  NI4709\n",
      "TDDLBGTAA  TDD861\n",
      "DAC7436A  DAC7436\n",
      "BXE1045AA  DAE1045\n",
      "CDL5248  DDL5848\n",
      "NE19103A  NEI9103\n",
      "NFW9824  NFW9824\n",
      "NAE2616  NAE2616\n",
      "NDX8504  NDX8504\n",
      "RFH277  RFH211\n",
      "ABG5030A  ABG5030\n",
      "DAH4645  DAH4645\n",
      "0AC234  UAC234\n",
      "J29DKTAA  129DKT\n",
      "153TZBAAA  153TZB\n",
      "340PZKAA  340PZK\n",
      "415NGDAA  415NGO\n",
      "AAHG0S8  AAH6098\n",
      "AA0T470A  AAO1410\n",
      "EE54G3AA  ACA5463\n",
      "EAD2225A  AHA2225\n",
      "APAGG72A  APA6672\n",
      "Y8EZES355AA  BC49695\n",
      "DAB1391A  DAB1391\n",
      "DAL8038A  DAL8038\n",
      "DAU1856  DAU1856\n",
      "LC213C5J  DBA3050\n",
      "DDL9445AA  DDL9445\n",
      "JEY3S3AAA  JEV333\n",
      "NAB9128  NAB9128\n",
      "QAHZ830AA  NAH7830\n",
      "NA87522A  NAO7522\n",
      "NAU4467  NAU4467\n",
      "ECECC9A  NBD8009\n",
      "NCA1238  NCA1238\n",
      "NCB7161A  NCB7161\n",
      "NCF5226A  NCF5226\n",
      "JNCN2857H  NCN2857\n",
      "NCU9737AA  NCU9737\n",
      "NDD7821  NDD7821\n",
      "NDR2268A  NDR2268\n",
      "NEA9103  NEA9103\n",
      "NED8751  NED8751\n",
      "NEF1096A  NEF1096\n",
      "NF94380AA  NF94380\n",
      "NFX5179A  NFX5179\n",
      "NGT59TAA  NG15917\n",
      "TTJS284A  TJS294\n",
      "TEN90AAA  TLN904\n",
      "TNVT74A  TNV174\n",
      "TYG561A  TYG561\n",
      "128\n",
      "786\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "real_images_val = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\valid\\\\*\\\\*.png')\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\*\\\\*\\\\*.png')\n",
    "ctr = 0\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    image = cv2.imread(file).astype('float32')\n",
    "    test_image = cv2.resize(image,(94,24))/256\n",
    "    test_image = np.expand_dims(test_image,axis=0)\n",
    "    preds = model.predict(test_image) \n",
    "    decoded = tf.keras.backend.ctc_decode(preds,(24,))\n",
    "    text = \"\"\n",
    "    for i in np.array(decoded[0]).reshape(24):\n",
    "        if i >-1:\n",
    "            text += DECODE_DICT[i]\n",
    "    if label == text:\n",
    "        ctr += 1\n",
    "    print(text,\" \"+ label)\n",
    "print(ctr)\n",
    "print(len(real_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_21744/3660101917.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  val_training_labels = np.array(val_labels)\n"
     ]
    }
   ],
   "source": [
    "val_training_set = np.array(val_data,dtype=np.float32)\n",
    "val_training_labels = np.array(val_labels)\n",
    "val_ragged = tf.ragged.constant(val_training_labels).to_tensor()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_training_set,val_ragged)).shuffle(640).batch(64)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83a3ba54cbd1f7dfc2d1ef373eda2962c312d1019df78bd28c6b3b15cf8d1ffd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
