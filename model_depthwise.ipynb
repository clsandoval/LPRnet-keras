{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import keras.backend as K\n",
    "from generator import DataGenerator\n",
    "PROJECT_NAME = \"LPRnet_keras\"\n",
    "MODEL_NAME = \"depthwise_model_rabdomchars_perspective_tflite\"\n",
    "\n",
    "IMAGE_SHAPE = [94,24]\n",
    "CHARS = \"ABCDEFGHIJKLMNPQRSTUVWXYZ0123456789\" # exclude I, O\n",
    "CHARS_DICT = {char:i for i, char in enumerate(CHARS)}\n",
    "DECODE_DICT = {i:char for i, char in enumerate(CHARS)}\n",
    "NUM_CLASS = len(CHARS)+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    # Compute the training-time loss value\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class small_basic_block(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,out_channels,name=None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        out_div4=int(out_channels/4)\n",
    "        self.main_layers = [\n",
    "            keras.layers.SeparableConv2D(out_div4,(1,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_div4,(3,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_div4,(1,3),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_channels,(1,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "        ]  \n",
    "    \n",
    "    def call(self,input):\n",
    "        x = input\n",
    "        for layer in self.main_layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test this later\n",
    "\n",
    "class global_context(keras.layers.Layer):\n",
    "    def __init__(self,kernel_size,stride,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ksize = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def call(self, input):\n",
    "        x = input \n",
    "        avg_pool = keras.layers.AveragePooling2D(pool_size=self.ksize,strides=self.stride,padding='same')(x)\n",
    "        sq = keras.layers.Lambda(lambda x: tf.math.square(x))(avg_pool)\n",
    "        sqm = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x))(sq)\n",
    "        out = keras.layers.Lambda(lambda x: tf.math.divide(x[0], x[1]))([avg_pool , sqm])\n",
    "        #out = keras.layers.Lambda(lambda x: K.l2_normalize(x,axis=1))(avg_pool)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"kernel_size\": self.ksize,\n",
    "            \"stride\": self.stride,\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LPRnet(keras.Model):\n",
    "    def __init__(self, input_shape=(24,94,3), **kwargs):\n",
    "        super(LPRnet, self).__init__(**kwargs)\n",
    "        self.input_layer = keras.layers.Input(input_shape)\n",
    "        self.cnn_layers= [\n",
    "            keras.layers.SeparableConv2D(64,kernel_size = (3,3),strides=1,padding='same',name='main_conv1',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(name='BN1'),\n",
    "            keras.layers.ReLU(name='RELU1'),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,1),name='maxpool2d_1',padding='same'),\n",
    "            small_basic_block(128),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,2),name='maxpool2d_2',padding='same'),\n",
    "            small_basic_block(256),\n",
    "            small_basic_block(256),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,2),name='maxpool2d_3',padding='same'),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.SeparableConv2D(256,(4,1),strides=1,padding='same',name='main_conv2',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.SeparableConv2D(NUM_CLASS,(1,13),padding='same',name='main_conv3',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),  \n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "        ]\n",
    "        self.out_layers = [\n",
    "            keras.layers.SeparableConv2D(NUM_CLASS,kernel_size=(1,1),strides=(1,1),padding='same',name='conv_out',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "        ]\n",
    "        self.out = self.call(self.input_layer)\n",
    "\n",
    "    def call(self,inputs,training=False):\n",
    "        x = inputs\n",
    "        layer_outputs = []\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "            layer_outputs.append(x)\n",
    "        scale1 = global_context((1,4),(1,4))(layer_outputs[0])\n",
    "        scale2 = global_context((1,4),(1,4))(layer_outputs[4])\n",
    "        scale3 = global_context((1,2),(1,2))(layer_outputs[6])\n",
    "        scale5 = global_context((1,2),(1,2))(layer_outputs[7])\n",
    "        sq = keras.layers.Lambda(lambda x: tf.math.square(x))(x)\n",
    "        sqm = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x))(sq)\n",
    "        scale4 = keras.layers.Lambda(lambda x: tf.math.divide(x[0], x[1]))([x , sqm])\n",
    "        gc_concat = keras.layers.Lambda(lambda x: tf.concat([x[0], x[1], x[2], x[3], x[4]],3))([scale1, scale2, scale3, scale5,scale4])\n",
    "        for layer in self.out_layers:\n",
    "            gc_concat = layer(gc_concat)\n",
    "        logits = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x[0],axis=1))([gc_concat])\n",
    "        logits = keras.layers.Softmax()(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_17960/2036217571.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training_labels = np.array(labels)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "\n",
    "real_images_val = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\valid\\\\*\\\\*.png')\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\marty\\\\*\\\\*.png')\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "val_data = []\n",
    "val_labels = []\n",
    "\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    label = label.replace(\"O\",\"0\")\n",
    "    image = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image,(94,24))/256\n",
    "    data.append(image)\n",
    "    labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "\n",
    "for file in real_images_val:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    label = label.replace(\"O\",\"0\")\n",
    "    image = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image,(94,24))\n",
    "    val_data.append(image)\n",
    "    val_labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "\n",
    "training_set = np.array(data,dtype=np.float32)\n",
    "training_labels = np.array(labels)\n",
    "ragged = tf.ragged.constant(training_labels).to_tensor()\n",
    "real_dataset = tf.data.Dataset.from_tensor_slices((training_set,ragged)).batch(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(MODEL_NAME):\n",
    "    model = keras.models.load_model(\n",
    "        MODEL_NAME, custom_objects={\"global_context\": global_context, \"CTCLoss\": CTCLoss  }\n",
    "    )\n",
    "else:\n",
    "    model = LPRnet()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),loss =CTCLoss)\n",
    "    model.build((1,24,94,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_17960/2355684483.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training_labels = np.array(gen_labels)\n"
     ]
    }
   ],
   "source": [
    "from gen_plates_keras import *\n",
    "gen = ImageGenerator()\n",
    "def generate_dataset(num = 100):\n",
    "    data, labels = gen.generate_images(num)\n",
    "    gen_labels = []\n",
    "    for label in labels:\n",
    "        gen_labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "    pics =np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    training_set = np.array(pics,dtype=np.float32)\n",
    "    training_labels = np.array(gen_labels)\n",
    "    ragged = tf.ragged.constant(training_labels).to_tensor()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((training_set,ragged)).shuffle(640).batch(64)\n",
    "    return dataset\n",
    "test_dataset = generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:19kjt7dk) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9004... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc1dc0f793c4d2f8e03a094175d12b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>182.30405</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>30.26264</td></tr><tr><td>val_loss</td><td>182.30405</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">wobbly-bird-1</strong>: <a href=\"https://wandb.ai/clsandoval/depthwise_model_rabdomchars_perspective_tflite/runs/19kjt7dk\" target=\"_blank\">https://wandb.ai/clsandoval/depthwise_model_rabdomchars_perspective_tflite/runs/19kjt7dk</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220206_080920-19kjt7dk\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:19kjt7dk). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/clsandoval/depthwise_model_rabdomchars_perspective_tflite/runs/3drlcadv\" target=\"_blank\">autumn-bush-2</a></strong> to <a href=\"https://wandb.ai/clsandoval/depthwise_model_rabdomchars_perspective_tflite\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=MODEL_NAME, entity=\"clsandoval\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 400,\n",
    "  \"batch_size\": 64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = DataGenerator()\n",
    "check = tf.keras.callbacks.ModelCheckpoint(\n",
    "    './trained_models/{}'.format(MODEL_NAME),\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=500,\n",
    "    options=None,\n",
    ")\n",
    "#model.fit(test_dataset)\n",
    "model.fit_generator(generator=generate,validation_data=real_dataset,validation_steps=5,epochs=100,steps_per_epoch=50,callbacks=[WandbCallback(),check])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as RELU1_layer_call_fn, RELU1_layer_call_and_return_conditional_losses, dropout_2_layer_call_fn, dropout_2_layer_call_and_return_conditional_losses, re_lu_26_layer_call_fn while saving (showing 5 of 85). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\carlos\\AppData\\Local\\Temp\\tmp089blr1s\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\carlos\\AppData\\Local\\Temp\\tmp089blr1s\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TFLITE_PATH = 'tflite_models'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"./{}/{}.tflite\".format(TFLITE_PATH,MODEL_NAME), 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AESEA  AAC1586\n",
      "A  040101007794\n",
      "A  04010464051\n",
      "A  459DLY\n",
      "A  4703LW\n",
      "A  5647WX\n",
      "A  AAO5592\n",
      "A  APA3772\n",
      "A  DAA4626\n",
      "A  DAF9190\n",
      "APA  DAJ1083\n",
      "A  DAL3300\n",
      "ATLA  DCP7079\n",
      "A  DWK95Q\n",
      "A  DXN659\n",
      "ASA  NBU4828\n",
      "A  NCG1221\n",
      "A  NCH8029\n",
      "NA  NCM9415\n",
      "A  NEH1815\n",
      "A  NFX7563\n",
      "A  NGS2592\n",
      "A  VDU712\n",
      "A  VEC862\n",
      "A  ZAZ220\n",
      "A  ZFZ596\n",
      "A  ZMY321\n",
      "A  04010101065\n",
      "A  04011094993\n",
      "A  18010044592\n",
      "ATZQA  AAJ5201\n",
      "AJP1A1A  AAP1274\n",
      "AZA  AAW1583\n",
      "1S1SA  ABA8615\n",
      "E12ZS1A  AEA9483\n",
      "A6AZA  AEA9512\n",
      "A  ARA6828\n",
      "AEASESA  ASA8680\n",
      "PEZ2TA  B6E247\n",
      "A1PA  CAQ6650\n",
      "ZPA1A  CPY711\n",
      "6AZA  DA57485\n",
      "AE1TJ6A  DAG3746\n",
      "A1A  DAH3150\n",
      "A129A  DAK1304\n",
      "A  DAL7407\n",
      "6ASZA  DAO6200\n",
      "A  DAY1428\n",
      "AE9ZLA  DCP5431\n",
      "4ATA  DCP7323\n",
      "A  DD66174\n",
      "A  DXX225\n",
      "A  DXY758\n",
      "AZEA  E2O801\n",
      "A  JAT99\n",
      "AZA  K1B519\n",
      "ASZ81A  NA36503\n",
      "NAE1Z1A  NAE1322\n",
      "3E2SA  NAE2008\n",
      "A  NAJ8740\n",
      "A  NBA4750\n",
      "A1AZA  NBK6857\n",
      "A  NBP3395\n",
      "ASA2DA  NBR9407\n",
      "ASAZS1A  NC04583\n",
      "E3JS1A  NCD4761\n",
      "NENSD4ZA  NCM8042\n",
      "ASA  NCM9147\n",
      "A  NDE9713\n",
      "A  NDF2712\n",
      "A  NDJ3111\n",
      "A  NDS1024\n",
      "A  NDV1148\n",
      "E1ZSA  NEA4294\n",
      "A  NED2300\n",
      "PFA1TZA  NED3275\n",
      "APA  NEH4482\n",
      "A  NGJ4631\n",
      "ATAEASA  P1E482\n",
      "AT1A1ZA  P3Y226\n",
      "PAZSPZA  RD2666\n",
      "AZA  TAJ800\n",
      "A  TIJ897\n",
      "A  TSM264\n",
      "ZSADFPA  TSN402\n",
      "ASA1SA  TTC958\n",
      "A  UIV416\n",
      "A  ZMW527\n",
      "A  153NDE\n",
      "ASA  ABR5310\n",
      "A  CAB1069\n",
      "A  CRP836\n",
      "A  NA02641\n",
      "APZS21CA  NBC2309\n",
      "A  NBF8676\n",
      "A  NDT7127\n",
      "A  NE26216\n",
      "A1A  13360564601\n",
      "A  ABE2313\n",
      "A  ABH1544\n",
      "A  NBI5456\n",
      "A  NBT2564\n",
      "A  NDT8216\n",
      "A  NEB8274\n",
      "A  NEJ2572\n",
      "A  NFT6109\n",
      "A  NHO560\n",
      "A  PIO960\n",
      "ATA  WIN754\n",
      "A  XSY504\n",
      "A  401DJL\n",
      "A1A  ADA5892\n",
      "AF1SA  APA7080\n",
      "A  CDZ5495\n",
      "A  DAL8625\n",
      "A  DRL923\n",
      "A  MJZ168\n",
      "AT6A1A  NAT6342\n",
      "AZE1SA  NCC1100\n",
      "A  NDC2372\n",
      "A6A  NEA5661\n",
      "A  TYN763\n",
      "A  ZKS104\n",
      "ATASZTA  0414052153\n",
      "SA10PDA  510TPD\n",
      "A2A  AAM4901\n",
      "ADSTSA  AAQ8870\n",
      "A12SA  AXA3085\n",
      "A1TA  DAA7239\n",
      "APA  DAG1195\n",
      "ATZAZA  DFY682\n",
      "SPZ6A  DNV820\n",
      "APA  DPU714\n",
      "AEA  DVU496\n",
      "JWNA1A  DWZ336\n",
      "ASEFZS3A  NBE1565\n",
      "EA261A  NCH2661\n",
      "ETSC2A  NCT8802\n",
      "AEF41BA  NGF4110\n",
      "AST2ALA  NGS8307\n",
      "A  SLG365\n",
      "NFNA  WFN441\n",
      "A  WKY191\n",
      "A  WUQ758\n",
      "A  13800893494\n",
      "A  307PZA\n",
      "A  BAC1219\n",
      "A  JFH823\n",
      "A  ZCV116\n",
      "A  853DPQ\n",
      "PAZCZA  A2Z021\n",
      "6ASA  AAJ9181\n",
      "A  CLM544\n",
      "A  DA10791\n",
      "A  DAA9889\n",
      "A  DAJ3327\n",
      "A  DAT1060\n",
      "A  DC70119\n",
      "A  GCS7606\n",
      "A  JDS115\n",
      "ATAZA  NAE1815\n",
      "AZASA  NAR3508\n",
      "AZATA  NAT1827\n",
      "EASA  NBA9743\n",
      "AS6ZA  NCR8656\n",
      "A  NDA1693\n",
      "AZATZA  NEX7507\n",
      "A  NFY2439\n",
      "A  NFY2439\n",
      "A  PJO114\n",
      "A  PJY785\n",
      "A  PST335\n",
      "A  TJP363\n",
      "A  TNN962\n",
      "A1A  TYR689\n",
      "A  UAR946\n",
      "A  UFG542\n",
      "A  XBP611\n",
      "A  XML355\n",
      "ASEA  ABH8899\n",
      "ASATSA  ABQ7659\n",
      "AZAN2SA  ABQ9626\n",
      "ASEA  AKA9280\n",
      "A  BEB959\n",
      "AH21A1A  DAH3342\n",
      "ASA  NAK4386\n",
      "A  NCP1449\n",
      "ATYNATA  P7X662\n",
      "A  TIW342\n",
      "A  UFH505\n",
      "APA  UPD333\n",
      "A  URT124\n",
      "A  VEP568\n",
      "AEA  WOG656\n",
      "A  XGE143\n",
      "AYSCZA  YT4054\n",
      "A  YZ0422\n",
      "A  ZDP310\n",
      "A  7635X\n",
      "A  AAY4074\n",
      "ATASA  AIA3251\n",
      "A  DAC3413\n",
      "4FJZ8A  DAF4129\n",
      "A  DAI9086\n",
      "A1ABA  DAJ4126\n",
      "A1A  DCP9554\n",
      "A  DYT333\n",
      "AZA79A  NBA7993\n",
      "A  NBV6196\n",
      "EA78P7A  NCW7897\n",
      "A  WBK918\n",
      "A  WLU208\n",
      "A  AGA6883\n",
      "A  AKA3673\n",
      "A  DA93819\n",
      "A  DBA1734\n",
      "A  DCP1485\n",
      "A  DDL6798\n",
      "A  DXP298\n",
      "A  NGY2496\n",
      "A  NI4709\n",
      "A  NNO149\n",
      "A  TDD861\n",
      "A  UPQ257\n",
      "A  VFE488\n",
      "A  ZEJ956\n",
      "A71A  DAC7436\n",
      "A  DAE1045\n",
      "A  DDL5848\n",
      "ET2SA  NEI9103\n",
      "ANALA  NFW9824\n",
      "A  UHW464\n",
      "A  UKG657\n",
      "AUEF1LA  NAE2616\n",
      "NDANESA  NDX8504\n",
      "SZA  RFH211\n",
      "A  SKE924\n",
      "AFA  A6I276\n",
      "S2ULA  ABG5030\n",
      "AH46A  DAH4645\n",
      "ALAZ1A  UAC234\n",
      "A  04011230625\n",
      "A  129DKT\n",
      "A  13011131579\n",
      "A  13801213902\n",
      "A  153TZB\n",
      "A  2536WS\n",
      "A  340PZK\n",
      "A  415NGO\n",
      "A  4168XC\n",
      "A1ASTZSA  AAH6098\n",
      "A  AAO1410\n",
      "A  ACA5463\n",
      "A  AHA2225\n",
      "A  APA6672\n",
      "A  BC49695\n",
      "A  BDB459\n",
      "AEA1A  DAB1391\n",
      "A  DAL8038\n",
      "A  DAU1856\n",
      "A  DBA3050\n",
      "A  DC60873\n",
      "A  DDL9445\n",
      "A  DLD251\n",
      "A  DVZ266\n",
      "A  DXN588\n",
      "A  DXT326\n",
      "A  GNA754\n",
      "ASATA  JEV333\n",
      "A  LEN38\n",
      "A  NAB9128\n",
      "A  NAH7830\n",
      "A  NAO7522\n",
      "A1ATA  NAU4467\n",
      "A  NBD8009\n",
      "A  NCA1238\n",
      "ASA  NCB7161\n",
      "A  NCF5226\n",
      "NALAZSEZA  NCN2857\n",
      "PASA  NCU9737\n",
      "A  NDD7821\n",
      "A  NDR2268\n",
      "A  NEA9103\n",
      "NEAZA  NED8751\n",
      "A  NEF1096\n",
      "A  NF94380\n",
      "AZASATA  NFX5179\n",
      "SZSTA  NG15917\n",
      "A  PMU139\n",
      "A  PNA113\n",
      "A  RJV271\n",
      "ANATA  S1Y770\n",
      "A  TIY659\n",
      "A  TJS294\n",
      "A  TKV342\n",
      "A  TLB988\n",
      "A  TLN904\n",
      "AY17A  TNV174\n",
      "A  TYG561\n",
      "A  UEM203\n",
      "A  UIN920\n",
      "A  VDU856\n",
      "A  WBP347\n",
      "A  WBR894\n",
      "A  WQR544\n",
      "A  XT4712\n",
      "A  ZEP890\n",
      "A  ZHE708\n",
      "7.974465370178223\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(\"C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\tflite_models\\\\depthwise_model_rabdomchars_perspective_tflite.tflite\")\n",
    "#interpreter = tf.lite.Interpreter(\"C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\tflite_models\\\\keras_lprnet_separable.tflite\")\n",
    "import numpy as np\n",
    "import time \n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\marty\\\\*\\\\*.png')\n",
    "start = time.time()\n",
    "ctr = 0\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    image = cv2.imread(file)\n",
    "    test_image = cv2.resize(image,(94,24))/256\n",
    "    test_image = np.expand_dims(test_image,axis=0)\n",
    "    test_image = test_image.astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    decoded = keras.backend.ctc_decode(output_data,(24,),greedy=False)\n",
    "    text = \"\"\n",
    "    for i in np.array(decoded[0]).reshape(24):\n",
    "        if i >-1:\n",
    "            text += DECODE_DICT[i]\n",
    "    if label == text:\n",
    "        ctr += 1\n",
    "    print(text, \" \"+ label)\n",
    "print(time.time()-start)\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'trained_models'\n",
    "TFLITE_PATH = 'tflite_models'\n",
    "model = keras.models.load_model(\n",
    "    os.path.join(MODEL_PATH, MODEL_NAME), custom_objects={\"global_context\": global_context, \"CTCLoss\": CTCLoss  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAC158G  AAC1586\n",
      "8AD1PB900T934  040101007794\n",
      "B421LAKXBAA  04010464051\n",
      "A5S0ZYAA  459DLY\n",
      "WG332WAAA  4703LW\n",
      "56417BXAA  5647WX\n",
      "AAQ5592  AAO5592\n",
      "APA3772A  APA3772\n",
      "FDAA4626  DAA4626\n",
      "DAF9190  DAF9190\n",
      "DAJ1083  DAJ1083\n",
      "DAL3300A  DAL3300\n",
      "DCP7079A  DCP7079\n",
      "DHKE5QAA  DWK95Q\n",
      "0XN652AA  DXN659\n",
      "RNBU4828  NBU4828\n",
      "NCG1221  NCG1221\n",
      "NCH8029A  NCH8029\n",
      "NCM9415A  NCM9415\n",
      "NEH1B15AA  NEH1815\n",
      "NFX7563A  NFX7563\n",
      "NGS2592  NGS2592\n",
      "HDUWTYTPFAAA  VDU712\n",
      "YEEEGGZA  VEC862\n",
      "AZHZ3ZZWA  ZAZ220\n",
      "ZF1595A  ZFZ596\n",
      "2MV3Z5TAAA  ZMY321\n",
      "2LQF1D10B5  04010101065\n",
      "2Z1EE2AAAA  04011094993\n",
      "9BTQQ219D3ZAA  18010044592\n",
      "AAJ5201A  AAJ5201\n",
      "AAP1274A  AAP1274\n",
      "AWM1583A  AAW1583\n",
      "ABA8GA5  ABA8615\n",
      "AEA9483AA  AEA9483\n",
      "AE195A2AA  AEA9512\n",
      "FAR15BZ8  ARA6828\n",
      "1A5A8G80  ASA8680\n",
      "BGE247AAA  B6E247\n",
      "CAQ6650  CAQ6650\n",
      "CPY717AA  CPY711\n",
      "0DAET485AA  DA57485\n",
      "DAG3746  DAG3746\n",
      "DAH3150  DAH3150\n",
      "DAK1304  DAK1304\n",
      "DAL7407  DAL7407\n",
      "DA06200F  DAO6200\n",
      "DAY1428AA  DAY1428\n",
      "DCP5431  DCP5431\n",
      "DCP7323  DCP7323\n",
      "B2E5HT4AAA  DD66174\n",
      "DXX22EA  DXX225\n",
      "QDXY75SBA  DXY758\n",
      "EB2QQJA9A  E2O801\n",
      "JWDL99DAA  JAT99\n",
      "BKBJAAA  K1B519\n",
      "7NVA30503  NA36503\n",
      "NAE1322  NAE1322\n",
      "NAE2008  NAE2008\n",
      "WAJ874DAA  NAJ8740\n",
      "NBA4750A  NBA4750\n",
      "NBK6857  NBK6857\n",
      "NBP3395A  NBP3395\n",
      "NBR9407A  NBR9407\n",
      "NC04583  NC04583\n",
      "NCD4761AA  NCD4761\n",
      "0NCM8042  NCM8042\n",
      "AEH9147A  NCM9147\n",
      "NDE9713A  NDE9713\n",
      "NDF2712  NDF2712\n",
      "NDJ311  NDJ3111\n",
      "NDS1024A  NDS1024\n",
      "ET114JAAA  NDV1148\n",
      "NEA4294  NEA4294\n",
      "NED2J0Q  NED2300\n",
      "NED3275  NED3275\n",
      "NEH4482  NEH4482\n",
      "NGJ4631A  NGJ4631\n",
      "AP16A825A  P1E482\n",
      "QP3Y228F  P3Y226\n",
      "H02GGBGAA  RD2666\n",
      "TAJB00A  TAJ800\n",
      "8TTZJKBBDEAA  TIJ897\n",
      "T5W26AAA  TSM264\n",
      "T5W4021A  TSN402\n",
      "DTCA95GAA  TTC958\n",
      "0XVR1EGAA  UIV416\n",
      "ZHDYJ4AAA  ZMW527\n",
      "153NDEA  153NDE\n",
      "ABR5JH0A  ABR5310\n",
      "CAB1069A  CAB1069\n",
      "EZHHAB35AA  CRP836\n",
      "NA02641AA  NA02641\n",
      "NBC2309  NBC2309\n",
      "NBFDB176AA  NBF8676\n",
      "NDT7127  NDT7127\n",
      "NE2G216AA  NE26216\n",
      "HJ1GQ5F1GQ1TP  13360564601\n",
      "1BEZ3DAAA  ABE2313\n",
      "ABH511A  ABH1544\n",
      "NB15456A  NBI5456\n",
      "N8T2564AA  NBT2564\n",
      "NDTB216AA  NDT8216\n",
      "NEB8Z7AAA  NEB8274\n",
      "ZEJZAAAA  NEJ2572\n",
      "NFT61092AA  NFT6109\n",
      "A4ZZ2AAAA  NHO560\n",
      "AS42B33AAA  PIO960\n",
      "W1NPT5AAA  WIN754\n",
      "XR5Y504AA  XSY504\n",
      "E1B1DJLAA  401DJL\n",
      "4B45852A  ADA5892\n",
      "APA7080A  APA7080\n",
      "CDZ5495  CDZ5495\n",
      "D0AL8625  DAL8625\n",
      "D71Z51ZD3AAA  DRL923\n",
      "HDZ758A  MJZ168\n",
      "NAT6342  NAT6342\n",
      "NCC1100AA  NCC1100\n",
      "H0E2372A  NDC2372\n",
      "2EA5661AA  NEA5661\n",
      "THXNH3AAA  TYN763\n",
      "Z2ELAAA  ZKS104\n",
      "0A1A052158  0414052153\n",
      "510TPDA  510TPD\n",
      "AAM450TA  AAM4901\n",
      "AAQ8870A  AAQ8870\n",
      "AXA30B5  AXA3085\n",
      "DAA7239  DAA7239\n",
      "10AG1952A  DAG1195\n",
      "DFY65Z2A  DFY682\n",
      "BNVEG3ZQA  DNV820\n",
      "Y0PU7TAA  DPU714\n",
      "0YLFA95A  DVU496\n",
      "DTVZ8515A  DWZ336\n",
      "NBE1565  NBE1565\n",
      "NCH2661  NCH2661\n",
      "NCT8802  NCT8802\n",
      "NGF4110  NGF4110\n",
      "NGS8307  NGS8307\n",
      "5EBZZ05AAA  SLG365\n",
      "HNFNAA1A  WFN441\n",
      "NKY6419AYA  WKY191\n",
      "W0QZT5BA  WUQ758\n",
      "1JBAQB9ZB1TA  13800893494\n",
      "A307PZAAA  307PZA\n",
      "0AC12D19AA  BAC1219\n",
      "JHHYBZ5AA  JFH823\n",
      "ZEVPU9AAA  ZCV116\n",
      "853DPQA  853DPQ\n",
      "A2Z021AA  A2Z021\n",
      "AAJ9781  AAJ9181\n",
      "EZM5AAAA  CLM544\n",
      "D1D0T5DAA  DA10791\n",
      "SDA49869A  DAA9889\n",
      "DAJ3DZ27AA  DAJ3327\n",
      "DAT1060  DAT1060\n",
      "PE70T729AA  DC70119\n",
      "GCS7606  GCS7606\n",
      "WD5XLEAAA  JDS115\n",
      "NAE1815  NAE1815\n",
      "NAR3508B  NAR3508\n",
      "NAT1827  NAT1827\n",
      "NBA9743A  NBA9743\n",
      "NCR8656  NCR8656\n",
      "NBA1963A  NDA1693\n",
      "NEX7507  NEX7507\n",
      "NFY2439A  NFY2439\n",
      "BNFT2439AA  NFY2439\n",
      "EPJQAHHAAAA  PJO114\n",
      "PJ1705AAA  PJY785\n",
      "P5T3358AA  PST335\n",
      "TJP3GJA  TJP363\n",
      "TMNM9G2AA  TNN962\n",
      "TYR689A  TYR689\n",
      "VWHQJFAAA  UAR946\n",
      "W0FEEDE7AAA  UFG542\n",
      "8P6TT1A  XBP611\n",
      "0PHA2EAAA  XML355\n",
      "ABH88B88  ABH8899\n",
      "ABQ7G58A  ABQ7659\n",
      "AB09G2GA  ABQ9626\n",
      "AKA9280  AKA9280\n",
      "BEBA951EA  BEB959\n",
      "DAH3342  DAH3342\n",
      "NAK4386A  NAK4386\n",
      "NCP1449  NCP1449\n",
      "ZPYXHG2A  P7X662\n",
      "EZ1WF14ZAA  TIW342\n",
      "UFH5U5AA  UFH505\n",
      "UPD353A  UPD333\n",
      "UHTT2AA  URT124\n",
      "WMEF55BA  VEP568\n",
      "DWUG2G5GMBA  WOG656\n",
      "1GE9ZGHAAA  XGE143\n",
      "2YTAQ54A  YT4054\n",
      "Y7Z7GXY22AA  YZ0422\n",
      "SZD0P3T0F  ZDP310\n",
      "76J5XXDAAA  7635X\n",
      "AAY4074  AAY4074\n",
      "AHA3251  AIA3251\n",
      "DAC3412AA  DAC3413\n",
      "DAF4129E  DAF4129\n",
      "DA190B6  DAI9086\n",
      "DAJ4126Y  DAJ4126\n",
      "DCP9554E  DCP9554\n",
      "DYT1133A  DYT333\n",
      "NBA7993  NBA7993\n",
      "NBV6196  NBV6196\n",
      "NCW7897AA  NCW7897\n",
      "N0E1STSAAA  WBK918\n",
      "HEU20GAA  WLU208\n",
      "AGAFH883AA  AGA6883\n",
      "13EA3AA  AKA3673\n",
      "D1S3GTSAA  DA93819\n",
      "08A1734  DBA1734\n",
      "PS1118EAA  DCP1485\n",
      "EDBZ679DAAA  DDL6798\n",
      "D1X1H3518GA  DXP298\n",
      "AH5P2496AA  NGY2496\n",
      "HNH1T89BAA  NI4709\n",
      "KAWX0RAZACAAA  NNO149\n",
      "TDD85AA  TDD861\n",
      "DP0ZZ5A7A  UPQ257\n",
      "1FF34B5AA  VFE488\n",
      "EZZZX1ZEAAA  ZEJ956\n",
      "DAC7436A  DAC7436\n",
      "0ZE1015AA  DAE1045\n",
      "EZ152418A  DDL5848\n",
      "NE19103AA  NEI9103\n",
      "NFW9824  NFW9824\n",
      "0HH1BAA  UHW464\n",
      "QA8SS3ZAA  UKG657\n",
      "NAE2616  NAE2616\n",
      "NDX8504  NDX8504\n",
      "RFH217A  RFH211\n",
      "2NEZ2B1AA  SKE924\n",
      "7AGZ78EAA  A6I276\n",
      "ABG5030  ABG5030\n",
      "DAH4645  DAH4645\n",
      "UAC234  UAC234\n",
      "Q40TF72ZJQGB25  04011230625\n",
      "129DAAAA  129DKT\n",
      "DJ0TFTAJT5Z5AA  13011131579\n",
      "HD1BZDP2BAA  13801213902\n",
      "153TZBAAA  153TZB\n",
      "Z53B5AAA  2536WS\n",
      "340PZKAA  340PZK\n",
      "A15NG0AAA  415NGO\n",
      "SHYAXEAA  4168XC\n",
      "AAH5G088  AAH6098\n",
      "A1Q14A0AA  AAO1410\n",
      "DE1E5ZG3AAA  ACA5463\n",
      "DHW225AAA  AHA2225\n",
      "APAGG72A  APA6672\n",
      "WHE48695AA  BC49695\n",
      "H05A459AA  BDB459\n",
      "DAB1391A  DAB1391\n",
      "BAL8038  DAL8038\n",
      "BAU1856  DAU1856\n",
      "E34ZEEEAA  DBA3050\n",
      "BEEG0BT3AAA  DC60873\n",
      "D0L9445A  DDL9445\n",
      "0ZBZ25AYA  DLD251\n",
      "QH42AAA  DVZ266\n",
      "0XN5BBA  DXN588\n",
      "0XT32EA  DXT326\n",
      "GNUAH75AA  GNA754\n",
      "JEY133AA  JEV333\n",
      "LZ4WESAA  LEN38\n",
      "NA2E912EAA  NAB9128\n",
      "9AH97A30A  NAH7830\n",
      "9A18752ZAA  NAO7522\n",
      "NAU4467J  NAU4467\n",
      "S21ZEZE9AA  NBD8009\n",
      "NCA1238  NCA1238\n",
      "NCB7161  NCB7161\n",
      "HEF5Z26P  NCF5226\n",
      "NCN2857  NCN2857\n",
      "NCU9737AA  NCU9737\n",
      "NDD7B21  NDD7821\n",
      "NDR2268A  NDR2268\n",
      "NEA9103  NEA9103\n",
      "NED8751  NED8751\n",
      "NEF1096A  NEF1096\n",
      "NF943B0A  NF94380\n",
      "NFX5179A  NFX5179\n",
      "NGT59T7AA  NG15917\n",
      "PMW0T31AA  PMU139\n",
      "PNAHT3AAA  PNA113\n",
      "HJVZHTAAA  RJV271\n",
      "STYTQA  S1Y770\n",
      "AF51AAA  TIY659\n",
      "FT3S224AA  TJS294\n",
      "TAPJ3SAAA  TKV342\n",
      "TLB9BBA  TLB988\n",
      "TZNSJ08AA  TLN904\n",
      "TNY174A  TNV174\n",
      "TYG561A  TYG561\n",
      "UEW203  UEM203\n",
      "HUHKE41H0AA  UIN920\n",
      "YUUE56AA  VDU856\n",
      "HPB3A7AA  WBP347\n",
      "N8HGSQAA  WBR894\n",
      "WUH544A  WQR544\n",
      "HEAAZD21AAA  XT4712\n",
      "ZEFABE0DAA  ZEP890\n",
      "ZHEDBAA  ZHE708\n",
      "90\n",
      "308\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "real_images_val = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\valid\\\\*\\\\*.png')\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\marty\\\\*\\\\*.png')\n",
    "ctr = 0\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    image = cv2.imread(file).astype('float32')\n",
    "    test_image = cv2.resize(image,(94,24))/256\n",
    "    test_image = np.expand_dims(test_image,axis=0)\n",
    "    preds = model.predict(test_image) \n",
    "    decoded = tf.keras.backend.ctc_decode(preds,(24,))\n",
    "    text = \"\"\n",
    "    for i in np.array(decoded[0]).reshape(24):\n",
    "        if i >-1:\n",
    "            text += DECODE_DICT[i]\n",
    "    if label == text or label == text[1:] or label == text[:-1]:\n",
    "        ctr += 1\n",
    "    print(text,\" \"+ label)\n",
    "print(ctr)\n",
    "print(len(real_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_21744/3660101917.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  val_training_labels = np.array(val_labels)\n"
     ]
    }
   ],
   "source": [
    "val_training_set = np.array(val_data,dtype=np.float32)\n",
    "val_training_labels = np.array(val_labels)\n",
    "val_ragged = tf.ragged.constant(val_training_labels).to_tensor()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_training_set,val_ragged)).shuffle(640).batch(64)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83a3ba54cbd1f7dfc2d1ef373eda2962c312d1019df78bd28c6b3b15cf8d1ffd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
