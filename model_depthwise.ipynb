{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import keras.backend as K\n",
    "from generator import DataGenerator\n",
    "PROJECT_NAME = \"LPRnet_keras\"\n",
    "MODEL_NAME = \"depthwise_model_randomchars_perspective_multiple_fonts\"\n",
    "\n",
    "IMAGE_SHAPE = [94,24]\n",
    "CHARS = \"ABCDEFGHIJKLMNPQRSTUVWXYZ0123456789\" # exclude I, O\n",
    "CHARS_DICT = {char:i for i, char in enumerate(CHARS)}\n",
    "DECODE_DICT = {i:char for i, char in enumerate(CHARS)}\n",
    "NUM_CLASS = len(CHARS)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    # Compute the training-time loss value\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class small_basic_block(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,out_channels,name=None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        out_div4=int(out_channels/4)\n",
    "        self.main_layers = [\n",
    "            keras.layers.SeparableConv2D(out_div4,(1,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_div4,(3,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_div4,(1,3),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_channels,(1,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "        ]  \n",
    "    \n",
    "    def call(self,input):\n",
    "        x = input\n",
    "        for layer in self.main_layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test this later\n",
    "\n",
    "class global_context(keras.layers.Layer):\n",
    "    def __init__(self,kernel_size,stride,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ksize = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def call(self, input):\n",
    "        x = input \n",
    "        avg_pool = keras.layers.AveragePooling2D(pool_size=self.ksize,strides=self.stride,padding='same')(x)\n",
    "        sq = keras.layers.Lambda(lambda x: tf.math.square(x))(avg_pool)\n",
    "        sqm = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x))(sq)\n",
    "        out = keras.layers.Lambda(lambda x: tf.math.divide(x[0], x[1]))([avg_pool , sqm])\n",
    "        #out = keras.layers.Lambda(lambda x: K.l2_normalize(x,axis=1))(avg_pool)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"kernel_size\": self.ksize,\n",
    "            \"stride\": self.stride,\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LPRnet(keras.Model):\n",
    "    def __init__(self, input_shape=(24,94,3), **kwargs):\n",
    "        super(LPRnet, self).__init__(**kwargs)\n",
    "        self.input_layer = keras.layers.Input(input_shape)\n",
    "        self.cnn_layers= [\n",
    "            keras.layers.SeparableConv2D(64,kernel_size = (3,3),strides=1,padding='same',name='main_conv1',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(name='BN1'),\n",
    "            keras.layers.ReLU(name='RELU1'),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,1),name='maxpool2d_1',padding='same'),\n",
    "            small_basic_block(128),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,2),name='maxpool2d_2',padding='same'),\n",
    "            small_basic_block(256),\n",
    "            small_basic_block(256),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,2),name='maxpool2d_3',padding='same'),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.SeparableConv2D(256,(4,1),strides=1,padding='same',name='main_conv2',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.SeparableConv2D(NUM_CLASS,(1,13),padding='same',name='main_conv3',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),  \n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "        ]\n",
    "        self.out_layers = [\n",
    "            keras.layers.SeparableConv2D(NUM_CLASS,kernel_size=(1,1),strides=(1,1),padding='same',name='conv_out',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "        ]\n",
    "        self.out = self.call(self.input_layer)\n",
    "\n",
    "    def call(self,inputs,training=False):\n",
    "        x = inputs\n",
    "        layer_outputs = []\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "            layer_outputs.append(x)\n",
    "        scale1 = global_context((1,4),(1,4))(layer_outputs[0])\n",
    "        scale2 = global_context((1,4),(1,4))(layer_outputs[4])\n",
    "        scale3 = global_context((1,2),(1,2))(layer_outputs[6])\n",
    "        scale5 = global_context((1,2),(1,2))(layer_outputs[7])\n",
    "        sq = keras.layers.Lambda(lambda x: tf.math.square(x))(x)\n",
    "        sqm = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x))(sq)\n",
    "        scale4 = keras.layers.Lambda(lambda x: tf.math.divide(x[0], x[1]))([x , sqm])\n",
    "        gc_concat = keras.layers.Lambda(lambda x: tf.concat([x[0], x[1], x[2], x[3], x[4]],3))([scale1, scale2, scale3, scale5,scale4])\n",
    "        for layer in self.out_layers:\n",
    "            gc_concat = layer(gc_concat)\n",
    "        logits = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x[0],axis=1))([gc_concat])\n",
    "        logits = keras.layers.Softmax()(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_24876/2036217571.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training_labels = np.array(labels)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "\n",
    "real_images_val = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\valid\\\\*\\\\*.png')\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\marty\\\\*\\\\*.png')\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "val_data = []\n",
    "val_labels = []\n",
    "\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    label = label.replace(\"O\",\"0\")\n",
    "    image = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image,(94,24))/256\n",
    "    data.append(image)\n",
    "    labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "\n",
    "for file in real_images_val:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    label = label.replace(\"O\",\"0\")\n",
    "    image = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image,(94,24))\n",
    "    val_data.append(image)\n",
    "    val_labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "\n",
    "training_set = np.array(data,dtype=np.float32)\n",
    "training_labels = np.array(labels)\n",
    "ragged = tf.ragged.constant(training_labels).to_tensor()\n",
    "real_dataset = tf.data.Dataset.from_tensor_slices((training_set,ragged)).batch(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(MODEL_NAME):\n",
    "    model = keras.models.load_model(\n",
    "        MODEL_NAME, custom_objects={\"global_context\": global_context, \"CTCLoss\": CTCLoss  }\n",
    "    )\n",
    "else:\n",
    "    model = LPRnet()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),loss =CTCLoss)\n",
    "    model.build((1,24,94,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_24876/2355684483.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training_labels = np.array(gen_labels)\n"
     ]
    }
   ],
   "source": [
    "from gen_plates_keras import *\n",
    "gen = ImageGenerator()\n",
    "def generate_dataset(num = 100):\n",
    "    data, labels = gen.generate_images(num)\n",
    "    gen_labels = []\n",
    "    for label in labels:\n",
    "        gen_labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "    pics =np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    training_set = np.array(pics,dtype=np.float32)\n",
    "    training_labels = np.array(gen_labels)\n",
    "    ragged = tf.ragged.constant(training_labels).to_tensor()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((training_set,ragged)).shuffle(640).batch(64)\n",
    "    return dataset\n",
    "test_dataset = generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mclsandoval\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/clsandoval/depthwise_model_randomchars_perspective_multiple_fonts/runs/21ruzeig\" target=\"_blank\">eternal-darkness-1</a></strong> to <a href=\"https://wandb.ai/clsandoval/depthwise_model_randomchars_perspective_multiple_fonts\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=MODEL_NAME, entity=\"clsandoval\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 400,\n",
    "  \"batch_size\": 64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 194ms/step - loss: 60.0428\n",
      "Epoch 1/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlos\\Desktop\\cs\\ml-sandbox\\ANPR\\LPRnet-keras\\generator.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training_labels = np.array(gen_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 16s 280ms/step - loss: 27.9636 - val_loss: 100.2028\n",
      "Epoch 2/11\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 22.8943 - val_loss: 100.2028\n",
      "Epoch 3/11\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 22.5133 - val_loss: 100.2007\n",
      "Epoch 4/11\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 22.2442 - val_loss: 100.0725\n",
      "Epoch 5/11\n",
      "50/50 [==============================] - 16s 322ms/step - loss: 22.1409 - val_loss: 99.1084\n",
      "Epoch 6/11\n",
      "50/50 [==============================] - 25s 489ms/step - loss: 22.1597 - val_loss: 97.3229\n",
      "Epoch 7/11\n",
      "50/50 [==============================] - 12s 247ms/step - loss: 21.9344 - val_loss: 88.6508\n",
      "Epoch 8/11\n",
      "50/50 [==============================] - 13s 262ms/step - loss: 22.0578 - val_loss: 71.5353\n",
      "Epoch 9/11\n",
      "50/50 [==============================] - 12s 247ms/step - loss: 21.9304 - val_loss: 57.6076\n",
      "Epoch 10/11\n",
      "50/50 [==============================] - ETA: 0s - loss: 21.6736"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_1_layer_call_fn, re_lu_1_layer_call_and_return_conditional_losses, re_lu_2_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./trained_models\\depthwise_model_randomchars_perspective_multiple_fonts\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./trained_models\\depthwise_model_randomchars_perspective_multiple_fonts\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 18s 353ms/step - loss: 21.6736 - val_loss: 53.2220\n",
      "Epoch 11/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlos\\Desktop\\cs\\ml-sandbox\\ANPR\\LPRnet-keras\\generator.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training_labels = np.array(gen_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 16s 322ms/step - loss: 21.3239 - val_loss: 44.1192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab44723b80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate = DataGenerator()\n",
    "check = tf.keras.callbacks.ModelCheckpoint(\n",
    "    './trained_models/{}'.format(MODEL_NAME),\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=500,\n",
    "    options=None,\n",
    ")\n",
    "model.fit(test_dataset)\n",
    "model.fit_generator(generator=generate,validation_data=real_dataset,validation_steps=3,epochs=11,steps_per_epoch=50,callbacks=[check])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_1_layer_call_fn, re_lu_1_layer_call_and_return_conditional_losses, re_lu_2_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\carlos\\AppData\\Local\\Temp\\tmpmwi4e7jm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\carlos\\AppData\\Local\\Temp\\tmpmwi4e7jm\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TFLITE_PATH = 'tflite_models'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"./{}/{}.tflite\".format(TFLITE_PATH,MODEL_NAME), 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  AAC1586\n",
      "TA  459DLY\n",
      "EA  AAO5592\n",
      "EA  APA3772\n",
      "A  DAA4626\n",
      "A  DAF9190\n",
      "A  DAJ1083\n",
      "A  DAL3300\n",
      "A  DCP7079\n",
      "A  NBU4828\n",
      "A  NCG1221\n",
      "9A  NCH8029\n",
      "A  NCM9415\n",
      "A  NEH1815\n",
      "EA  NFX7563\n",
      "A  NGS2592\n",
      "A  AAJ5201\n",
      "A  AAP1274\n",
      "TA  AAW1583\n",
      "TZA  ABA8615\n",
      "A  AEA9483\n",
      "ZA  AEA9512\n",
      "A  ARA6828\n",
      "A  ASA8680\n",
      "TA  CAQ6650\n",
      "TZA  CPY711\n",
      "A  DAG3746\n",
      "TA  DAH3150\n",
      "A  DAK1304\n",
      "A  DAL7407\n",
      "TA  DAO6200\n",
      "A  DAY1428\n",
      "A  DCP5431\n",
      "EA  DCP7323\n",
      "A  NA36503\n",
      "A  NAE1322\n",
      "EA  NAE2008\n",
      "EA  NAJ8740\n",
      "A  NBA4750\n",
      "TA  NBK6857\n",
      "A  NBP3395\n",
      "A  NBR9407\n",
      "A  NC04583\n",
      "A  NCD4761\n",
      "A  NCM8042\n",
      "A  NCM9147\n",
      "A  NDE9713\n",
      "A  NDF2712\n",
      "A  NDJ3111\n",
      "TA  NDS1024\n",
      "TA  NDV1148\n",
      "EA  NEA4294\n",
      "TA  NED2300\n",
      "A  NED3275\n",
      "A  NEH4482\n",
      "TA  NGJ4631\n",
      "A  TSN402\n",
      "A  153NDE\n",
      "EA  ABR5310\n",
      "A  CAB1069\n",
      "TA  NA02641\n",
      "UA  NBC2309\n",
      "TA  NBF8676\n",
      "A  NDT7127\n",
      "A  NE26216\n",
      "A  ABE2313\n",
      "9A  ABH1544\n",
      "TA  NBI5456\n",
      "TA  NBT2564\n",
      "TA  NDT8216\n",
      "EA  NEB8274\n",
      "TA  NFT6109\n",
      "TA  401DJL\n",
      "TA  ADA5892\n",
      "ZA  APA7080\n",
      "A  CDZ5495\n",
      "TA  DAL8625\n",
      "TA  DRL923\n",
      "TA  MJZ168\n",
      "A  NAT6342\n",
      "TA  NCC1100\n",
      "TA  NDC2372\n",
      "TA  NEA5661\n",
      "TA  510TPD\n",
      "A  AAM4901\n",
      "A  AAQ8870\n",
      "A  AXA3085\n",
      "EA  DAA7239\n",
      "TA  DAG1195\n",
      "A  NBE1565\n",
      "9A  NCH2661\n",
      "A  NCT8802\n",
      "EZA  NGF4110\n",
      "A  NGS8307\n",
      "A  307PZA\n",
      "A  BAC1219\n",
      "TA  ZCV116\n",
      "EA  A2Z021\n",
      "TA  AAJ9181\n",
      "A  CLM544\n",
      "A  DAA9889\n",
      "TA  DAJ3327\n",
      "A  DAT1060\n",
      "TA  DC70119\n",
      "TA  GCS7606\n",
      "A  NAE1815\n",
      "A  NAR3508\n",
      "TA  NAT1827\n",
      "A  NBA9743\n",
      "QA  NCR8656\n",
      "TA  NDA1693\n",
      "A  NEX7507\n",
      "TA  NFY2439\n",
      "TA  NFY2439\n",
      "TA  TJP363\n",
      "A  TYR689\n",
      "A  ABH8899\n",
      "EA  ABQ7659\n",
      "A  ABQ9626\n",
      "TA  AKA9280\n",
      "A  DAH3342\n",
      "EA  NAK4386\n",
      "A  NCP1449\n",
      "ZA  URT124\n",
      "A  YT4054\n",
      "A  AAY4074\n",
      "A  AIA3251\n",
      "TA  DAC3413\n",
      "A  DAF4129\n",
      "TEA  DAI9086\n",
      "A  DAJ4126\n",
      "A  DCP9554\n",
      "A  DYT333\n",
      "9A  NBA7993\n",
      "EA  NBV6196\n",
      "EA  NCW7897\n",
      "EA  AGA6883\n",
      "TA  AKA3673\n",
      "TA  DBA1734\n",
      "TA  DCP1485\n",
      "TA  DDL6798\n",
      "A  NGY2496\n",
      "EA  NI4709\n",
      "A  TDD861\n",
      "TA  DAC7436\n",
      "TA  DAE1045\n",
      "TA  DDL5848\n",
      "TA  NEI9103\n",
      "TA  NFW9824\n",
      "A  NAE2616\n",
      "A  NDX8504\n",
      "EA  RFH211\n",
      "A  ABG5030\n",
      "A  DAH4645\n",
      "A  UAC234\n",
      "TA  129DKT\n",
      "TA  153TZB\n",
      "TA  340PZK\n",
      "A  415NGO\n",
      "TA  AAH6098\n",
      "TA  AAO1410\n",
      "A  ACA5463\n",
      "ZA  AHA2225\n",
      "A  APA6672\n",
      "TA  BC49695\n",
      "TZA  DAB1391\n",
      "TA  DAL8038\n",
      "TA  DAU1856\n",
      "EA  DBA3050\n",
      "TA  DDL9445\n",
      "A  JEV333\n",
      "TA  NAB9128\n",
      "A  NAH7830\n",
      "EA  NAO7522\n",
      "A  NAU4467\n",
      "TA  NBD8009\n",
      "EA  NCA1238\n",
      "A  NCB7161\n",
      "A  NCF5226\n",
      "A  NCN2857\n",
      "ZA  NCU9737\n",
      "A  NDD7821\n",
      "TA  NDR2268\n",
      "UA  NEA9103\n",
      "A  NED8751\n",
      "A  NEF1096\n",
      "TA  NF94380\n",
      "TA  NFX5179\n",
      "A  NG15917\n",
      "TA  TJS294\n",
      "A  TLN904\n",
      "TA  TNV174\n",
      "A  TYG561\n",
      "7.338671684265137\n",
      "0 193\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(\"C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\tflite_models\\\\{}.tflite\".format(MODEL_NAME))\n",
    "#interpreter = tf.lite.Interpreter(\"C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\tflite_models\\\\keras_lprnet_separable.tflite\")\n",
    "import numpy as np\n",
    "import time \n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\marty\\\\*\\\\*.png')\n",
    "start = time.time()\n",
    "ctr = 0\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    image = cv2.imread(file)\n",
    "    test_image = cv2.resize(image,(94,24))/256\n",
    "    test_image = np.expand_dims(test_image,axis=0)\n",
    "    test_image = test_image.astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    decoded = keras.backend.ctc_decode(output_data,(24,),greedy=False)\n",
    "    text = \"\"\n",
    "    for i in np.array(decoded[0]).reshape(24):\n",
    "        if i >-1:\n",
    "            text += DECODE_DICT[i]\n",
    "    if label == text:\n",
    "        ctr += 1\n",
    "    print(text, \" \"+ label)\n",
    "print(time.time()-start)\n",
    "print(ctr,len(real_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'trained_models'\n",
    "TFLITE_PATH = 'tflite_models'\n",
    "model = keras.models.load_model(\n",
    "    os.path.join(MODEL_PATH, MODEL_NAME), custom_objects={\"global_context\": global_context, \"CTCLoss\": CTCLoss  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587S05LAA  07303\n",
      "7301Q85B125  1303\n",
      "130340843  1303\n",
      "566TPEAA  566TPE\n",
      "35TNMSA  57\n",
      "EE800NGMAA  59\n",
      "A103573AA  AA03573\n",
      "AAK17053A  AAK7053\n",
      "AAE4G73A  AAL4673\n",
      "ATG3TN5A  ACG3105\n",
      "AB352S3A  AD35293\n",
      "DAL5017A  DAL5017\n",
      "DAMA00  DAM7900\n",
      "DC18721  DC18721\n",
      "G1GT5EA  G2G725\n",
      "WAF6171  NAF6171\n",
      "NBK7446  NBK7446\n",
      "MG5725ZA  NC57254\n",
      "NCG109Z  NCG1092\n",
      "NCZ5306  NCZ5306\n",
      "SS83253GA  NDB3253\n",
      "NE70G3GA  NE70636\n",
      "NE70G3GA  NE84727\n",
      "NEJ9900  NEJ9900\n",
      "MF2Y85A  NH\n",
      "PYY50TA  PYV501\n",
      "WSNMBAA  TJX496\n",
      "VW50T54A  WSO154\n",
      "ZUVZ5TAA  ZJV257\n",
      "TG30QRDR955A  1303\n",
      "943N0XA  943NOX\n",
      "UDAE3011  DAE3011\n",
      "NAH7401  NAH7401\n",
      "W8G1384  NBG1384\n",
      "NBV2323U  NBV2323\n",
      "NC16514  NCI6514\n",
      "FNCJ9396  NCJ9396\n",
      "LNCU375B  NCU3758\n",
      "ND11397  NDI1397\n",
      "4SQT580E7AA  NDT5180\n",
      "NDU6721A  NDU6721\n",
      "ZNET1791A  NET1793\n",
      "NGG6277A  NGG6277\n",
      "TTXSKQTAA  TYX907\n",
      "0GEB09AA  UGF809\n",
      "BET339AA  WET339\n",
      "659RZUFA  XSC203\n",
      "Y5G054  YS6054\n",
      "AAH7062  AAH7062\n",
      "AAZ2G55  AAZ2655\n",
      "ABG5953  ABG5953\n",
      "ACZEQBAA  ACZ4349\n",
      "2P1BT75A  APA8716\n",
      "NAD1140  NAD1140\n",
      "N86M27805  NBQ2703\n",
      "TNCY8S40  NCY8340\n",
      "NDG3354  NDG3354\n",
      "UU2B45A  UIT846\n",
      "0VC545AA  UVC646\n",
      "0HK675AA  UWK673\n",
      "TXSJT22  XSJ122\n",
      "UEZGUV8A  ZBT716\n",
      "ERJ695A  ZRJ695\n",
      "1303F0572790  1303\n",
      "AAN8821  AAN8821\n",
      "U3V72TQA  AAW1219\n",
      "AAW4G2S  AAW4629\n",
      "ABLB425A  ABL8429\n",
      "AB0G833  ABO6833\n",
      "AXA2G23A  AXA2623\n",
      "GP16Q192AAA  B1G115\n",
      "F85H59TZAA  B5H597\n",
      "WBBVMT1JAA  B6V113\n",
      "CCN6359A  CCN6359\n",
      "DAH3990  DAH3990\n",
      "DA14759  DAI4759\n",
      "DAJ4086A  DAJ4086\n",
      "G0XK4Z21  DAK4221\n",
      "UDAE4B57A  DAK4857\n",
      "DJXBAA  DJX849\n",
      "6440QHE35  DNS315\n",
      "DPY74T7A8A  DPV741\n",
      "B587A  DSV307\n",
      "NAK7704A  NAK7704\n",
      "NA07760  NAO7760\n",
      "NBG5119  NBG5119\n",
      "NDT1475  NDI1475\n",
      "NEA4707  NEA4707\n",
      "NED9729  NED9729\n",
      "P1P7B8BEAA  P1P786\n",
      "PNMW850A  PNM850\n",
      "TTTEAT5ZA  TIE152\n",
      "T06856A  TO6856\n",
      "UBG628A  UBG628\n",
      "0FR1M5AA  UER469\n",
      "LUZAT63AA  UQZ163\n",
      "WY21DT7LAA  VFN171\n",
      "3H8V5EAA  WGV361\n",
      "WGY544A  WGV544\n",
      "WLB333A  WLB333\n",
      "LWU9530A  WOC930\n",
      "MTT334AA  WTT334\n",
      "CZDT386  XFT404\n",
      "XX3U282AAA  XKU282\n",
      "GH7Y4EU0LAA  XRV697\n",
      "Z0Z1445A  ZGZ449\n",
      "0A9464755T  0414\n",
      "8JE2061P0AA  2061HQ\n",
      "01315ZAA  7131523\n",
      "AAA5G24A  AAA5624\n",
      "ADW97G5  AAH9765\n",
      "AAP38T1AA  AAP3811\n",
      "AAY9543A  AAV9943\n",
      "ABD3G87A  ABD3687\n",
      "ABDB382A  ABD8382\n",
      "ABEGG47EA  ABE6647\n",
      "E8DH4224A  ABH4224\n",
      "ABST55TT  ABS1591\n",
      "UABT2085A  ABT2089\n",
      "8CA55T3A  ACA5513\n",
      "ACA950SA  ACA9509\n",
      "EC2Z470A  ACB4710\n",
      "ADF1594ZA  AFA9422\n",
      "ARA2473  ARA2473\n",
      "5DA73GSA  AUA7369\n",
      "B3QENU4B21A  CAC9414\n",
      "EUEF554  CNB956\n",
      "XDA3GT3T  DA36137\n",
      "Z1A32B1AA  DAA3281\n",
      "DAA6079  DAA6079\n",
      "DA790Z  DAA7902\n",
      "DAB3117  DAB3117\n",
      "DAB9203  DAB9203\n",
      "DAF3151  DAF3151\n",
      "0AT6912A  DAI6912\n",
      "DAJ1537  DAJ3537\n",
      "D1J6237A  DAJ6287\n",
      "DAM4661P  DAM4661\n",
      "DAN6674A  DAN6674\n",
      "DAN9661  DAN966I\n",
      "DA08297A  DAO8297\n",
      "DCSD0ST5A  DC98919\n",
      "DCQ5208  DCQ5208\n",
      "QTTTB9NA  DTJ189\n",
      "YZ25A  DVZ253\n",
      "BX08AA  E2K336\n",
      "FTTG43G5AA  F11643\n",
      "FJETAAA  FJF161\n",
      "CUAC5057V  IAC5057\n",
      "FK7S75GAA  K1S750\n",
      "NAA8802  NAA8602\n",
      "NADZ7BHQA  NAD7889\n",
      "N1G8532  NAG8632\n",
      "QNZH517D  NAH5170\n",
      "NAK7472  NAK7472\n",
      "EW1LB482  NAL8482\n",
      "NAQ368DA  NAQ3680\n",
      "NAQ4851  NAQ4851\n",
      "NWAW6798  NAW6798\n",
      "NAZ3097A  NAZ3097\n",
      "DNBC3031  NBC3031\n",
      "BH1332A  NBH1332\n",
      "NBQ1076A  NBQ1076\n",
      "NBR9005  NBR9005\n",
      "NBR9005  NBR9005\n",
      "NCC5153  NCC5153\n",
      "NCK8809  NCK8809\n",
      "NCN4242  NCN4242\n",
      "UNC0XG555A  NCO4558\n",
      "NCY7023  NCY7023\n",
      "NDD3762  NDD3762\n",
      "NM2EGA  NDH384\n",
      "NDKZ919  NDK4919\n",
      "NDE1031  NDL1031\n",
      "NEA5358  NEA5358\n",
      "NGF6077A  NGF6077\n",
      "NGJ9244  NGJ9244\n",
      "NUB5U5A  NII609\n",
      "EQKGB14AA  NK6884\n",
      "NVUB0EA  NVQ802\n",
      "P6A83GWAA  P6A833\n",
      "E1LN56TAA  PIL567\n",
      "EP00331A  POO331\n",
      "P8PB35TA  POP935\n",
      "REP127TA  PPJ937\n",
      "P0P535  PQP935\n",
      "00UT99AA  TOQ799\n",
      "TRWTZ3TA  TRW123\n",
      "0TCB65A  TTC866\n",
      "1MUZET18  U2L148\n",
      "TYFS5ZA  UIF452\n",
      "0T045Z0A  UIO570\n",
      "GUKEAB8AA  UKE484\n",
      "D3G15PAA  UKG469\n",
      "CUE0NZJAAA  ULQ724\n",
      "E0K6T65G  UMI168\n",
      "D06Z30F5AA  UOE405\n",
      "UAZU0A  UTY200\n",
      "LA1EAA  VFG420\n",
      "TVEG3Z0A  VFG420\n",
      "WWS3BZAA  VFN382\n",
      "D05N2TBT  WDN218\n",
      "EWJ0ZBZ3  WJO282\n",
      "K6H3WFA  XBN872\n",
      "GSXGE7G0  XGE460\n",
      "ZXKD232A  XKD232\n",
      "TPVFU9AAA  XMV847\n",
      "RX1S9GWAA  XPX984\n",
      "YZ75875AA  YZ7587\n",
      "EZ10495ZUA  ZGH827\n",
      "ZHAM3B5A  ZHA385\n",
      "URW58A  ZKN158\n",
      "L55UETJAA  ZSJ373\n",
      "010103BA  010103\n",
      "B8583R58A  0301\n",
      "BUS1GTSGZL  04011290399\n",
      "MQ5J204G53  13030204653\n",
      "136605A  136605\n",
      "290C1QA  29OCIQ\n",
      "49EZG158AA  4940SR\n",
      "A2J023  A2J023\n",
      "A3JA0TA  A3J401\n",
      "A3Q04TA  A3O047\n",
      "A5L070A  A5L070\n",
      "VAAA5G5B  AAA6698\n",
      "AAB715GA  AAB7156\n",
      "U1TBGU2A  AAI8602\n",
      "AAYB2Z4  AAY8244\n",
      "MAAY5424  AAY9424\n",
      "ABDG531  ABD6531\n",
      "ABDG531  ABD6531\n",
      "ABG20B0A  ABG2080\n",
      "ABG7G83  ABG7683\n",
      "ABH5238  ABH9238\n",
      "AB0T3G5  ABO1365\n",
      "DAB07280  ABO7280\n",
      "AB0TDA5A  ABQ1049\n",
      "AB0D35  ABU1049\n",
      "ACC9144  ACC9144\n",
      "ACD2587  ACD2587\n",
      "AK75TQA  ACK7570\n",
      "DHABGTBAA  AHA8618\n",
      "LR8E0AA  AIR355\n",
      "AKA3077  AKA3077\n",
      "ARA5G77T  ARA5677\n",
      "WATA8556  ATA8556\n",
      "FB4UTG9A  B4U769\n",
      "FAE16H8A  CAG1698\n",
      "FCAK6752  CAK6752\n",
      "CD22454  CDJ2454\n",
      "CWK5GTRQD0A  CNK561\n",
      "DAM7478  DAM7478\n",
      "DCP1383  DCP1383\n",
      "1AC1809  IAC1809\n",
      "KT025SAA  K1Q255\n",
      "NA18468A  NAI8468\n",
      "NAK4217  NAK4217\n",
      "NAP9900  NAP9900\n",
      "NAV6098A  NAV0698\n",
      "N8G6290A  NBG6290\n",
      "NBT862UA  NBT8620\n",
      "NBY4971  NBY4971\n",
      "NBZ3785L  NBZ3785\n",
      "G4GS2D7Z2AA  NCG2307\n",
      "NCM8560  NCM8560\n",
      "ZNCQ1872M  NCQ1872\n",
      "ND202GSAA  ND2069\n",
      "NDA3544R  NDA3544\n",
      "NDG3903  NDG3903\n",
      "ENDN7293E  NDN7293\n",
      "NDP6220  NDP6220\n",
      "D0EUBAA  NDZ1056\n",
      "WE531TZA  NE59313\n",
      "NEH7107A  NEH7107\n",
      "BNE673WAA  NEX7747\n",
      "HTNGL1528  NGL1528\n",
      "MNUU339WA  NOO399\n",
      "VNR90G8LAA  NR9068\n",
      "QP1FGA15  P1F641\n",
      "EP7F693XAA  P7F693\n",
      "PV0A5ZAA  PMO952\n",
      "P6EEB5A5AA  POE223\n",
      "FWFN98B5A  RMP968\n",
      "G5WS1BH7AAA  SHS873\n",
      "TAZAB51A  TAZ864\n",
      "TLU333  TLU333\n",
      "0TESB20AA  TYS820\n",
      "ETYYZ2  TYV412\n",
      "E1Z1GAA  TYZ746\n",
      "UJ845A  UJI849\n",
      "0WF505A  UWF505\n",
      "0YAS5BA  UYA998\n",
      "WUTB75A  WQT879\n",
      "XEC395AA  XCC295\n",
      "RJX55ECAA  YX5656\n",
      "UZHEGY0AA  ZHE810\n",
      "ZHX1Z56A  ZHX756\n",
      "FW2N6955A  ZJN955\n",
      "ZJW1955  ZJW955\n",
      "030141Q12008  0401\n",
      "G13030B41033  1303\n",
      "71505DBB5BD  1303\n",
      "EZG19YYAA  2629XY\n",
      "J532NEAA  7532NE\n",
      "GA0N0G8  A0N068\n",
      "AAA75G7  AAA7567\n",
      "AAC95G9  AAC9569\n",
      "AAKG50SA  AAK6509\n",
      "EA05380  AAO9380\n",
      "E1DFE3J  AAP6303\n",
      "AAX2GG3  AAX2663\n",
      "DF521A  AAY5204\n",
      "AAZ2B30A  AAZ2830\n",
      "ABC7355  ABC7355\n",
      "U8BD45T2A  ABD4512\n",
      "ABG70G7TA  ABG7067\n",
      "KABT6G58  ABI9699\n",
      "AB0G025  ABO6025\n",
      "BT707B  ABT7078\n",
      "ACC8SS4AA  ACC8554\n",
      "DA4057TA  ADA4057\n",
      "AEAB8T54  AEA8194\n",
      "AFA555  AHA5169\n",
      "DAKA2GG5  AKA9869\n",
      "NBK8135  ANBK8135\n",
      "00A0A5535  AOA5935\n",
      "BADA7S85  AOA7985\n",
      "ARA3323  ARA3323\n",
      "U1S05548L  ASA5948\n",
      "1S19283  ASA9283\n",
      "E3V32BZ4AA  AVA2844\n",
      "AYA3740A  AVA3740\n",
      "6CT901RAAA  C1T903\n",
      "CA0Y6691A  CAO6691\n",
      "CAP7941  CAP7941\n",
      "CAR4515  CAR4515\n",
      "C1G666A  CIG666\n",
      "JCJ5960MA  CJ5900\n",
      "CJ5900  CJS900\n",
      "DDAD2961A  DAD2961\n",
      "DAD3517  DAD3517\n",
      "DAF8862  DAF8862\n",
      "DAG8779  DAG8779\n",
      "DA13387  DAI3387\n",
      "DAJ3840  DAJ3840\n",
      "DAJ8485  DAJ8485\n",
      "DAL3958AA  DAL3958\n",
      "DAL9511  DAL9511\n",
      "DAN2477  DAN2477\n",
      "DAZ125AF  DAZ1254\n",
      "5DBZ56322  DBZ5632\n",
      "DD50T57A  DD50157\n",
      "DDL9971  DDL9971\n",
      "DGE35QAA  DGE350\n",
      "8DGJJ85GA  DGJ186\n",
      "DTB574  DTB574\n",
      "DVH590AA  DVH690\n",
      "BXTAB8AA  DXT488\n",
      "DXW3Z0AA  DXW427\n",
      "BM1Z1AA  DXW427\n",
      "AECA26AA  ECA26\n",
      "EZCB8BA  EZC888\n",
      "EEHB5B8AA  FEH888\n",
      "FJ09330A  FJD330\n",
      "FRK2GBA  FRK248\n",
      "GA01457  GAO1457\n",
      "GCG21ATA  GCG21\n",
      "GED6857  GED6857\n",
      "1AC78762  IAC7876\n",
      "EJD01971  JDO1971\n",
      "WAV7020Q  NA7020\n",
      "NAB5970A  NAB5970\n",
      "NAB837B  NAB8378\n",
      "NAC5407  NAC5407\n",
      "NAE3124  NAE3124\n",
      "NAE3970  NAE3970\n",
      "NAK4228A  NAK4228\n",
      "NAL1727A  NAL1727\n",
      "NAN9317  NAN9317\n",
      "WAP8301  NAP8301\n",
      "8NAQ6323M  NAQ6323\n",
      "N8V1S79A  NAV1579\n",
      "NAV2808  NAV2808\n",
      "WAV28BBA  NAV2888\n",
      "ZNAV3156  NAV3156\n",
      "NAY6252  NAY6252\n",
      "NAZ2072  NAZ2072\n",
      "NAZ6492  NAZ6492\n",
      "NBF7744  NBF7744\n",
      "NBH6470  NBH6470\n",
      "N51B452  NBI3452\n",
      "N8K8135  NBK8135\n",
      "NB03076A  NBO3076\n",
      "NBP4517  NBP4517\n",
      "NBP8290A  NBP8290\n",
      "NBQ3076  NBQ3076\n",
      "NBW2508A  NBW250B\n",
      "NCB53TBAA  NC85518\n",
      "NCC3638  NCC3638\n",
      "NCF7371  NCF7371\n",
      "NCJ2777  NCJ2777\n",
      "NCJ5296  NCJ5296\n",
      "NCN7186  NCN7186\n",
      "GNC01444  NCO1444\n",
      "RNC01652P  NCO1652\n",
      "ENC01652E  NCO1652\n",
      "NC019B1  NCO1981\n",
      "NC05754  NCO5754\n",
      "NCR5029  NCR5029\n",
      "NCS2063A  NCS2063\n",
      "NCU9931  NCU9931\n",
      "NCV1992  NCV1992\n",
      "NDC5973  NDC5973\n",
      "NDM1741T  NDM1741\n",
      "NDN12371  NDN1237\n",
      "NDU2906  NDU2906\n",
      "NDU8361A  NDU8361\n",
      "NDU9234  NDU9234\n",
      "WDV2062  NDV2062\n",
      "NEA2431  NEA2431\n",
      "NEC6356  NEC6356\n",
      "NEJ8420  NEJ8420\n",
      "NEU6437A  NEU6437\n",
      "NFU5518  NFU5518\n",
      "JNFW1871W  NFW1871\n",
      "NFY2649  NFY2649\n",
      "1NGB1199  NGB1199\n",
      "NGG4780  NGG4780\n",
      "NGG7107A  NGG7107\n",
      "NU0UQG5AA  NGO885\n",
      "NUEZG7A  NHQ287\n",
      "1NTXT23  NIX123\n",
      "EENE507T5AA  NL9071\n",
      "NHT6594A  NMI694\n",
      "N0K6T43A  NOK143\n",
      "1UVGG6AA  NOO885\n",
      "N0X35TA  NOX351\n",
      "GYE8G0A  NYE860\n",
      "KU38U8AA  OGA77\n",
      "B0Y1A775  OY1477\n",
      "GPSES28E  P5E528\n",
      "GCP5PB83A  P5P863\n",
      "YP8GG00AA  P6G600\n",
      "5PGE7943G  P6L114\n",
      "KP06055Z2AA  P8O055\n",
      "E0A1ZAA  PHO232\n",
      "CE02925AA  PLO929\n",
      "P0T54TAA  PQT541\n",
      "PQX50TTAA  PQX901\n",
      "PUY52Z3  PQY624\n",
      "EHH3DDAA  PRW311\n",
      "BYL38BA  PYL388\n",
      "UBAK5250AA  RAK925\n",
      "KEFE5T9A  RFE979\n",
      "E5JB25AA  SJB215\n",
      "5UB2T5AAA  SJB215\n",
      "U1T6MAAA  TAI176\n",
      "T13955A  TOI495\n",
      "WJTUP569A  TQP549\n",
      "TXYT3AA  TXT437\n",
      "TTKA35GA  TYK436\n",
      "0GRGG7AA  UHR581\n",
      "M4YE1G8TA  UIL681\n",
      "ZU1RZ8T72A  UIY247\n",
      "UKX68AA  UKX430\n",
      "0DTS5TA  UOT570\n",
      "JUYB37TA  UVB371\n",
      "0VE832A  UVL934\n",
      "0WFB6TA  UWF881\n",
      "0WJB67A  UWJ867\n",
      "MG0287A  WGD242\n",
      "WEUEUUAA  WII300\n",
      "EUSA5691AA  WIJ569\n",
      "ELF5GLAA  WIK581\n",
      "MJB52AA  WJR152\n",
      "MVW04796A  WMO796\n",
      "KFY895AA  WPN848\n",
      "K9C15VA  XBC957\n",
      "XEX69G9A  XLX969\n",
      "TXEB35AA  XNC833\n",
      "0WE530T9AA  XNL534\n",
      "X65Y6Z7AAA  XSP627\n",
      "5YUT5A5  YU7945\n",
      "NY33Z58AA  YZ3708\n",
      "ZK315EG5AA  ZAN589\n",
      "ZZ0RB52A  ZDR859\n",
      "ZEZ4953AA  ZEL953\n",
      "515AAA  ZJA416\n",
      "7PE29Z6A  ZMC926\n",
      "042810AAA  042810\n",
      "5Z836A  6X8467\n",
      "73873QCAA  7673QC\n",
      "998DKXA  998DKX\n",
      "UCBZ75  AAC8475\n",
      "AACS541  AAC9541\n",
      "ABE7329A  ABE7329\n",
      "ZABE7325A  ABE7329\n",
      "G2AHAB4B9  AHA9489\n",
      "LD0VAS5784M  AVA5704\n",
      "BGU485A  B6U485\n",
      "EB7A557LA  B7A597\n",
      "CA1T6024  CAI6024\n",
      "DAA5756  DAA5756\n",
      "DAA6207AA  DAA6207\n",
      "DAB6695  DAB6695\n",
      "DAC8346TA  DAC8346\n",
      "DAC9591  DAC9591\n",
      "DAG99B3  DAG9983\n",
      "DAK2002A  DAK2002\n",
      "DAK4631  DAK4631\n",
      "DAL1937A  DAL1937\n",
      "DAN2120  DAN2120\n",
      "Q2142849  DAN2849\n",
      "DAN4020  DAN4020\n",
      "DA05827  DAO5827\n",
      "DAT1647  DAT1647\n",
      "DAT7458  DAT7458\n",
      "DAZ9022  DAZ9022\n",
      "DBA5608  DBA5608\n",
      "DBA8632UA  DBA8632\n",
      "DBZ8883  DBZ8883\n",
      "DCB3312  DCB3312\n",
      "DCQ2268A  DCQ2268\n",
      "DCQ374DAA  DCQ3740\n",
      "DCQ9890  DCQ9890\n",
      "DDL46B6  DDL4686\n",
      "DDL546B  DDL5468\n",
      "DEB1684AA  DEB1684\n",
      "ED5C504G5AA  DSC904\n",
      "UDVV5BB3A  DVV688\n",
      "FT1T96G5AA  F3T408\n",
      "EG2W52BGAA  G2W528\n",
      "MURBL6A  HOT88\n",
      "EJHBE4UAA  JM8241\n",
      "NAF3554  NAF3554\n",
      "ZNAH21ZSA  NAH4143\n",
      "NAL9515  NAL9515\n",
      "NAX5446  NAX5446\n",
      "NBC6046A  NBC6046\n",
      "NBJ35A9A  NBJ355\n",
      "NBT7864A  NBT7866\n",
      "NCA3963A  NCA3963\n",
      "NCB4238  NCB4238\n",
      "ENCLGG4T  NCI664\n",
      "TNCGG4  NCI664\n",
      "NCJ8265  NCJ8265\n",
      "NCT8023A  NCT8023\n",
      "NCU4340  NCU4340\n",
      "NDU1689UA  NDU1689\n",
      "5WPF6697F5  NEA6697\n",
      "NEG4765  NEG4765\n",
      "NEH6898  NEH6898\n",
      "NET8936  NEI8936\n",
      "NGF9950  NGF9950\n",
      "NGN2484  NGN2484\n",
      "5116ZZAA  NRI622\n",
      "NUT353A  NUI393\n",
      "FP9R0Q1AA  P9R001\n",
      "FFT3B7TA  PPT487\n",
      "YP0FB74A  PQF874\n",
      "PRW35ULA  PRW350\n",
      "REEF4224  REF224\n",
      "RGJ554AA  RGJ994\n",
      "E51E229AGA  S1F220\n",
      "G5H5T5ZA  SHS197\n",
      "5JD3TGAA  SJD418\n",
      "TSJY3TZA  SJV372\n",
      "TT0A300  TIO300\n",
      "TLD7T5A  TLD719\n",
      "GTM0T75A  TMU175\n",
      "TQL321  TQL321\n",
      "TRU7G2A  TRU762\n",
      "DEM385FA  UEM345\n",
      "LU0N569AA  UGN669\n",
      "8HE795A  UHE795\n",
      "SUU53Z7A  UOS323\n",
      "8S352AA  USJ552\n",
      "YFA832A  VFA832\n",
      "YV5WF0NAA  VOY901\n",
      "WBQ307  WBQ301\n",
      "WK0X409AA  WKO409\n",
      "WM14532A  WMI532\n",
      "MFN5WW4A  WPN874\n",
      "XCZ221A  XCZ221\n",
      "X0E2G8  XDF269\n",
      "STGA83ZAA  XTG837\n",
      "NYC2A2T  YC2412\n",
      "ZAB103A  ZAB103\n",
      "ZED5G3A  ZED963\n",
      "7EE25BAA  ZEM256\n",
      "EZHU8ZZ0A  ZHU220\n",
      "EZ5JW33BA  ZJM338\n",
      "EFU5ZJA  ZPD628\n",
      "AAC15BG  AAC1586\n",
      "A59BEYAA  459DLY\n",
      "VA1055526  AAO5592\n",
      "APA3772A  APA3772\n",
      "DAA4626D  DAA4626\n",
      "DAF9190  DAF9190\n",
      "DAJ1083  DAJ1083\n",
      "DAL3300A  DAL3300\n",
      "DCP7079L  DCP7079\n",
      "5NBU4828  NBU4828\n",
      "NCG1221  NCG1221\n",
      "NCH8029  NCH8029\n",
      "NCM9415  NCM9415\n",
      "NEH1B15  NEH1815\n",
      "NFX7563  NFX7563\n",
      "NGS2592  NGS2592\n",
      "AAJ5201A  AAJ5201\n",
      "AAPJ1274A  AAP1274\n",
      "UAWJ5B3  AAW1583\n",
      "TABA8GT5  ABA8615\n",
      "AEA5483  AEA9483\n",
      "AEA95T2A  AEA9512\n",
      "ZARAGB2BF  ARA6828\n",
      "JASA8G80T  ASA8680\n",
      "CAQ6650  CAQ6650\n",
      "CPYY7T1A  CPY711\n",
      "DAG3746  DAG3746\n",
      "DAH3150  DAH3150\n",
      "DAK1304R  DAK1304\n",
      "DAL7407  DAL7407\n",
      "MDA06200B  DAO6200\n",
      "TDAY1428  DAY1428\n",
      "DCP5431  DCP5431\n",
      "DCP7323  DCP7323\n",
      "NA3G503  NA36503\n",
      "NAE1322A  NAE1322\n",
      "NAE2008  NAE2008\n",
      "NAJ874DA  NAJ8740\n",
      "NBA4750A  NBA4750\n",
      "NBK6857  NBK6857\n",
      "NBP3395  NBP3395\n",
      "NBR9407  NBR9407\n",
      "NC04583  NC04583\n",
      "NCD4761A  NCD4761\n",
      "NCM8042  NCM8042\n",
      "NCM9147  NCM9147\n",
      "NDE97153  NDE9713\n",
      "NDF2712  NDF2712\n",
      "NDJ3111  NDJ3111\n",
      "NDS1024  NDS1024\n",
      "HWDY114B  NDV1148\n",
      "NEA4294A  NEA4294\n",
      "NED2300A  NED2300\n",
      "NED3275  NED3275\n",
      "ENEH44B2  NEH4482\n",
      "GNGJ4631  NGJ4631\n",
      "T5H402TA  TSN402\n",
      "153NDEAA  153NDE\n",
      "ABR53T0A  ABR5310\n",
      "CAB1069  CAB1069\n",
      "NA02641  NA02641\n",
      "NBC2309  NBC2309\n",
      "TNBFB676F  NBF8676\n",
      "NDT7127  NDT7127\n",
      "NE2G21GA  NE26216\n",
      "UB8E23T3  ABE2313\n",
      "AGHFS4A4A  ABH1544\n",
      "NB15456  NBI5456\n",
      "NBT2564  NBT2564\n",
      "NDT8216  NDT8216\n",
      "NEBBZ74  NEB8274\n",
      "NFT6109  NFT6109\n",
      "81DJLA  401DJL\n",
      "A0A5852  ADA5892\n",
      "APA7080A  APA7080\n",
      "CDZ5495  CDZ5495\n",
      "CDAL8625  DAL8625\n",
      "DR1L9Z3AA  DRL923\n",
      "KSZ1G8  MJZ168\n",
      "NAT6342  NAT6342\n",
      "NCC1100  NCC1100\n",
      "NDC2372  NDC2372\n",
      "GEAE5561A  NEA5661\n",
      "510TPDA  510TPD\n",
      "AAM450TA  AAM4901\n",
      "AAQBB70  AAQ8870\n",
      "TAXA3085  AXA3085\n",
      "DAA7239  DAA7239\n",
      "LDAG12953A  DAG1195\n",
      "NBE1565  NBE1565\n",
      "NCH2661  NCH2661\n",
      "NCT8802  NCT8802\n",
      "NGF4110  NGF4110\n",
      "NGS8307  NGS8307\n",
      "X367PZAA  307PZA\n",
      "BXC1219  BAC1219\n",
      "MZ6JWLAAA  ZCV116\n",
      "A2Z021AA  A2Z021\n",
      "AAJ5TBT  AAJ9181\n",
      "CEM53AA  CLM544\n",
      "1DAA9889  DAA9889\n",
      "BDXJ3327  DAJ3327\n",
      "DAT1060  DAT1060\n",
      "DC70T19  DC70119\n",
      "GCS7606  GCS7606\n",
      "BNAE1815A  NAE1815\n",
      "NAR3508A  NAR3508\n",
      "NAT1827  NAT1827\n",
      "NBA9743  NBA9743\n",
      "NCR8656  NCR8656\n",
      "NDA1963  NDA1693\n",
      "FNEX7507  NEX7507\n",
      "NFY2439  NFY2439\n",
      "QNFY2439  NFY2439\n",
      "TJP3G3AA  TJP363\n",
      "TYR689AA  TYR689\n",
      "ABH8855  ABH8899\n",
      "ABQ7G59  ABQ7659\n",
      "ABQ5G2GA  ABQ9626\n",
      "AKA9280  AKA9280\n",
      "DAH3342  DAH3342\n",
      "NAK43B6A  NAK4386\n",
      "NCP1449  NCP1449\n",
      "K7HT28MAA  URT124\n",
      "EYTA054  YT4054\n",
      "AAY4074  AAY4074\n",
      "WATA3251  AIA3251\n",
      "DAC34T3  DAC3413\n",
      "DAF4129E  DAF4129\n",
      "DAT9036  DAI9086\n",
      "DDAJ4126U  DAJ4126\n",
      "DCP9554F  DCP9554\n",
      "DYT333A  DYT333\n",
      "NBA7993  NBA7993\n",
      "NBV6196  NBV6196\n",
      "NCW7897A  NCW7897\n",
      "AGAGB83  AGA6883\n",
      "EE3G73A  AKA3673\n",
      "DBA1734  DBA1734\n",
      "DCP1485  DCP1485\n",
      "CDZ679QA  DDL6798\n",
      "NGY2496  NGY2496\n",
      "GN3TQ8BA  NI4709\n",
      "JTDDBG1AA  TDD861\n",
      "DAC7436  DAC7436\n",
      "D1E1045  DAE1045\n",
      "DDL584B  DDL5848\n",
      "NE19103  NEI9103\n",
      "NFW9824  NFW9824\n",
      "NNAE2616  NAE2616\n",
      "NDX8504  NDX8504\n",
      "RFH2TTY  RFH211\n",
      "ABG5030A  ABG5030\n",
      "DDAH4645  DAH4645\n",
      "Y0AC234  UAC234\n",
      "129DRYAA  129DKT\n",
      "153TZBAA  153TZB\n",
      "340PZKAA  340PZK\n",
      "415NG0AA  415NGO\n",
      "AAHG058  AAH6098\n",
      "AA0T4T0  AAO1410\n",
      "DE154G3A  ACA5463\n",
      "AHA2225AA  AHA2225\n",
      "APAGG72  APA6672\n",
      "YBEZ9355A  BC49695\n",
      "DAB1391  DAB1391\n",
      "DAL8038  DAL8038\n",
      "DAU1856  DAU1856\n",
      "MTT3550  DBA3050\n",
      "DDL9435  DDL9445\n",
      "JEV335AA  JEV333\n",
      "NAB9128  NAB9128\n",
      "3AHZ830  NAH7830\n",
      "NA07522  NAO7522\n",
      "NAU4467  NAU4467\n",
      "S32E009A  NBD8009\n",
      "NCA1238  NCA1238\n",
      "NCB7161  NCB7161\n",
      "NCF5226  NCF5226\n",
      "4NCN2857H  NCN2857\n",
      "NCU9737A  NCU9737\n",
      "NDD7821  NDD7821\n",
      "NDR2268A  NDR2268\n",
      "NEA9103  NEA9103\n",
      "NED8751  NED8751\n",
      "NEF1096A  NEF1096\n",
      "NF94380A  NF94380\n",
      "NFX5179  NFX5179\n",
      "NGT59T  NG15917\n",
      "TTSS254A  TJS294\n",
      "TEN908A  TLN904\n",
      "TNV174A  TNV174\n",
      "TYG561A  TYG561\n",
      "182\n",
      "786\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "real_images_val = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\marty\\\\*\\\\*.png')\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\*\\\\*\\\\*.png')\n",
    "ctr = 0\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    image = cv2.imread(file).astype('float32')\n",
    "    test_image = cv2.resize(image,(94,24))/256\n",
    "    test_image = np.expand_dims(test_image,axis=0)\n",
    "    preds = model.predict(test_image) \n",
    "    decoded = tf.keras.backend.ctc_decode(preds,(24,))\n",
    "    text = \"\"\n",
    "    for i in np.array(decoded[0]).reshape(24):\n",
    "        if i >-1:\n",
    "            text += DECODE_DICT[i]\n",
    "    if label == text:\n",
    "        ctr += 1\n",
    "    print(text,\" \"+ label)\n",
    "print(ctr)\n",
    "print(len(real_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_21744/3660101917.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  val_training_labels = np.array(val_labels)\n"
     ]
    }
   ],
   "source": [
    "val_training_set = np.array(val_data,dtype=np.float32)\n",
    "val_training_labels = np.array(val_labels)\n",
    "val_ragged = tf.ragged.constant(val_training_labels).to_tensor()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_training_set,val_ragged)).shuffle(640).batch(64)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83a3ba54cbd1f7dfc2d1ef373eda2962c312d1019df78bd28c6b3b15cf8d1ffd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
