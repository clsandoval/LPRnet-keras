{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import keras.backend as K\n",
    "from generator import DataGenerator\n",
    "\n",
    "MODEL_NAME = \"depthwise_model_rabdomchars_perspective\"\n",
    "\n",
    "IMAGE_SHAPE = [94,24]\n",
    "CHARS = \"ABCDEFGHIJKLMNPQRSTUVWXYZ0123456789\" # exclude I, O\n",
    "CHARS_DICT = {char:i for i, char in enumerate(CHARS)}\n",
    "DECODE_DICT = {i:char for i, char in enumerate(CHARS)}\n",
    "NUM_CLASS = len(CHARS)+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    # Compute the training-time loss value\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class small_basic_block(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,out_channels,name=None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        out_div4=int(out_channels/4)\n",
    "        self.main_layers = [\n",
    "            keras.layers.SeparableConv2D(out_div4,(1,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_div4,(3,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_div4,(1,3),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_channels,(1,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "        ]  \n",
    "    \n",
    "    def call(self,input):\n",
    "        x = input\n",
    "        for layer in self.main_layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test this later\n",
    "\n",
    "class global_context(keras.layers.Layer):\n",
    "    def __init__(self,kernel_size,stride,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ksize = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def call(self, input):\n",
    "        x = input \n",
    "        avg_pool = keras.layers.AveragePooling2D(pool_size=self.ksize,strides=self.stride,padding='same')(x)\n",
    "        sq = keras.layers.Lambda(lambda x: tf.math.square(x))(avg_pool)\n",
    "        sqm = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x))(sq)\n",
    "        out = keras.layers.Lambda(lambda x: tf.math.divide(x[0], x[1]))([avg_pool , sqm])\n",
    "        #out = keras.layers.Lambda(lambda x: K.l2_normalize(x,axis=1))(avg_pool)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"kernel_size\": self.ksize,\n",
    "            \"stride\": self.stride,\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LPRnet(keras.Model):\n",
    "    def __init__(self, input_shape=(24,94,3), **kwargs):\n",
    "        super(LPRnet, self).__init__(**kwargs)\n",
    "        self.input_layer = keras.layers.Input(input_shape)\n",
    "        self.cnn_layers= [\n",
    "            keras.layers.SeparableConv2D(64,kernel_size = (3,3),strides=1,padding='same',name='main_conv1',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(name='BN1'),\n",
    "            keras.layers.ReLU(name='RELU1'),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,1),name='maxpool2d_1',padding='same'),\n",
    "            small_basic_block(128),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,2),name='maxpool2d_2',padding='same'),\n",
    "            small_basic_block(256),\n",
    "            small_basic_block(256),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,2),name='maxpool2d_3',padding='same'),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.SeparableConv2D(256,(4,1),strides=1,padding='same',name='main_conv2',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.SeparableConv2D(NUM_CLASS,(1,13),padding='same',name='main_conv3',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),  \n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "        ]\n",
    "        self.out_layers = [\n",
    "            keras.layers.SeparableConv2D(NUM_CLASS,kernel_size=(1,1),strides=(1,1),padding='same',name='conv_out',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "        ]\n",
    "        self.out = self.call(self.input_layer)\n",
    "\n",
    "    def call(self,inputs,training=False):\n",
    "        x = inputs\n",
    "        layer_outputs = []\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "            layer_outputs.append(x)\n",
    "        scale1 = global_context((1,4),(1,4))(layer_outputs[0])\n",
    "        scale2 = global_context((1,4),(1,4))(layer_outputs[4])\n",
    "        scale3 = global_context((1,2),(1,2))(layer_outputs[6])\n",
    "        scale5 = global_context((1,2),(1,2))(layer_outputs[7])\n",
    "        sq = keras.layers.Lambda(lambda x: tf.math.square(x))(x)\n",
    "        sqm = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x))(sq)\n",
    "        scale4 = keras.layers.Lambda(lambda x: tf.math.divide(x[0], x[1]))([x , sqm])\n",
    "        gc_concat = keras.layers.Lambda(lambda x: tf.concat([x[0], x[1], x[2], x[3], x[4]],3))([scale1, scale2, scale3, scale5,scale4])\n",
    "        for layer in self.out_layers:\n",
    "            gc_concat = layer(gc_concat)\n",
    "        logits = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x[0],axis=1))([gc_concat])\n",
    "        logits = keras.layers.Softmax()(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_11472/2036217571.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training_labels = np.array(labels)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "\n",
    "real_images_val = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\valid\\\\*\\\\*.png')\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\marty\\\\*\\\\*.png')\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "val_data = []\n",
    "val_labels = []\n",
    "\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    label = label.replace(\"O\",\"0\")\n",
    "    image = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image,(94,24))/256\n",
    "    data.append(image)\n",
    "    labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "\n",
    "for file in real_images_val:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    label = label.replace(\"O\",\"0\")\n",
    "    image = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image,(94,24))\n",
    "    val_data.append(image)\n",
    "    val_labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "\n",
    "training_set = np.array(data,dtype=np.float32)\n",
    "training_labels = np.array(labels)\n",
    "ragged = tf.ragged.constant(training_labels).to_tensor()\n",
    "real_dataset = tf.data.Dataset.from_tensor_slices((training_set,ragged)).batch(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(MODEL_NAME):\n",
    "    model = keras.models.load_model(\n",
    "        MODEL_NAME, custom_objects={\"global_context\": global_context, \"CTCLoss\": CTCLoss  }\n",
    "    )\n",
    "else:\n",
    "    model = LPRnet()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),loss =CTCLoss)\n",
    "    model.build((1,24,94,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_11472/2355684483.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training_labels = np.array(gen_labels)\n"
     ]
    }
   ],
   "source": [
    "from gen_plates_keras import *\n",
    "gen = ImageGenerator()\n",
    "def generate_dataset(num = 100):\n",
    "    data, labels = gen.generate_images(num)\n",
    "    gen_labels = []\n",
    "    for label in labels:\n",
    "        gen_labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "    pics =np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    training_set = np.array(pics,dtype=np.float32)\n",
    "    training_labels = np.array(gen_labels)\n",
    "    ragged = tf.ragged.constant(training_labels).to_tensor()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((training_set,ragged)).shuffle(640).batch(64)\n",
    "    return dataset\n",
    "test_dataset = generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mclsandoval\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/clsandoval/depthwise_model_rabdomchars_perspective/runs/7onrx0x7\" target=\"_blank\">vague-armadillo-5</a></strong> to <a href=\"https://wandb.ai/clsandoval/depthwise_model_rabdomchars_perspective\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=MODEL_NAME, entity=\"clsandoval\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 400,\n",
    "  \"batch_size\": 64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = DataGenerator()\n",
    "check = tf.keras.callbacks.ModelCheckpoint(\n",
    "    './{}'.format(MODEL_NAME),\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=500,\n",
    "    options=None,\n",
    ")\n",
    "model.fit_generator(generator=generate,validation_data=real_dataset,validation_steps=5,epochs=10000,steps_per_epoch=50,callbacks=[WandbCallback(),check])\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as RELU1_layer_call_and_return_conditional_losses, RELU1_layer_call_fn, dropout_layer_call_and_return_conditional_losses, dropout_layer_call_fn, re_lu_12_layer_call_and_return_conditional_losses while saving (showing 5 of 85). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\carlos\\AppData\\Local\\Temp\\tmpew6g2xkf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\carlos\\AppData\\Local\\Temp\\tmpew6g2xkf\\assets\n",
      "WARNING:absl:Found untraced functions such as RELU1_layer_call_and_return_conditional_losses, RELU1_layer_call_fn, dropout_layer_call_and_return_conditional_losses, dropout_layer_call_fn, re_lu_12_layer_call_and_return_conditional_losses while saving (showing 5 of 85). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: depthwise_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: depthwise_model\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "model.save(MODEL_NAME)\n",
    "\n",
    "with open(\"{}.tflite\".format(MODEL_NAME), 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(\"keras_lprnet_vanilla.tflite\")\n",
    "import numpy as np\n",
    "import time \n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\marty\\\\*\\\\*.png')\n",
    "start = time.time()\n",
    "ctr = 0\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    image = cv2.imread(file)\n",
    "    test_image = cv2.resize(image,(94,24))/256\n",
    "    test_image = np.expand_dims(test_image,axis=0)\n",
    "    test_image = test_image.astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    decoded = keras.backend.ctc_decode(output_data,(24,),greedy=False)\n",
    "    text = \"\"\n",
    "    for i in np.array(decoded[0]).reshape(24):\n",
    "        if i >-1:\n",
    "            text += DECODE_DICT[i]\n",
    "    if label == text:\n",
    "        ctr += 1\n",
    "    print(text, \" \"+ label)\n",
    "print(time.time()-start)\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'trained_models'\n",
    "TFLITE_PATH = 'tflite_models'\n",
    "model = keras.models.load_model(\n",
    "    os.path.join(MODEL_PATH, MODEL_NAME), custom_objects={\"global_context\": global_context, \"CTCLoss\": CTCLoss  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AACJJ58G  AAC1586\n",
      "R8DJ0T03ZS4  040101007794\n",
      "SKF24GCEY1A  04010464051\n",
      "A5SDLYTA  459DLY\n",
      "AGZSSEWGAA  4703LW\n",
      "564ZTEXAA  5647WX\n",
      "A105592T  AAO5592\n",
      "APA3772  APA3772\n",
      "DAA4626U  DAA4626\n",
      "DAF9190  DAF9190\n",
      "EDAJ1083  DAJ1083\n",
      "DAL3300A  DAL3300\n",
      "DCP7079  DCP7079\n",
      "DHKE05QAAA  DWK95Q\n",
      "0XNG5EA  DXN659\n",
      "ENBU4828  NBU4828\n",
      "NCG1221  NCG1221\n",
      "NCH8029  NCH8029\n",
      "NCM9415  NCM9415\n",
      "NEH1815  NEH1815\n",
      "NFX7563  NFX7563\n",
      "NGS2592  NGS2592\n",
      "WHHH16PZBR2A  VDU712\n",
      "GWEFEGG2VA  VEC862\n",
      "ZEZ1ZZ5GAA  ZAZ220\n",
      "HF15F2GA  ZFZ596\n",
      "EHRSZ5AAA  ZMY321\n",
      "E8F1F8AA  04010101065\n",
      "EECC820AAA  04011094993\n",
      "Z56E66A55F  18010044592\n",
      "AAJ5201A  AAJ5201\n",
      "AAP1274A  AAP1274\n",
      "AAW1583  AAW1583\n",
      "ABA8GT5  ABA8615\n",
      "AEAS483  AEA9483\n",
      "AEAS5T2A  AEA9512\n",
      "ARAGE28F  ARA6828\n",
      "PLASA8G80  ASA8680\n",
      "BGE247A  B6E247\n",
      "CAG6650  CAQ6650\n",
      "CPY7T1A  CPY711\n",
      "DAE7485AA  DA57485\n",
      "DAG3746  DAG3746\n",
      "DAH3150  DAH3150\n",
      "LDAK1304GZ  DAK1304\n",
      "DAL7407  DAL7407\n",
      "GLDA06200E  DAO6200\n",
      "ADAY1428  DAY1428\n",
      "DCP5431  DCP5431\n",
      "DCP7323  DCP7323\n",
      "D6E6T72A  DD66174\n",
      "0XX225A  DXX225\n",
      "GXYTD5EA  DXY758\n",
      "BG988A  E2O801\n",
      "5WHRR5AAA  JAT99\n",
      "HKFE5264WA  K1B519\n",
      "NA36583  NA36503\n",
      "NAE1322  NAE1322\n",
      "NAE2008  NAE2008\n",
      "NAJ874D  NAJ8740\n",
      "NBA4750A  NBA4750\n",
      "NBK6857  NBK6857\n",
      "NBP3395  NBP3395\n",
      "NBR9407  NBR9407\n",
      "NC04583E  NC04583\n",
      "NCD4761A  NCD4761\n",
      "NCM8042  NCM8042\n",
      "NCM9147  NCM9147\n",
      "NDE9715  NDE9713\n",
      "NDF2712  NDF2712\n",
      "NDJ3111  NDJ3111\n",
      "NDS1024  NDS1024\n",
      "WGV114QAA  NDV1148\n",
      "NEA4294A  NEA4294\n",
      "WED2300  NED2300\n",
      "NED3275  NED3275\n",
      "NEH4482  NEH4482\n",
      "5NGJ4631F  NGJ4631\n",
      "GBR1E822A  P1E482\n",
      "QP3Y228E  P3Y226\n",
      "RD2GGAA  RD2666\n",
      "TAJB00A  TAJ800\n",
      "5ETT5FGFMZ5  TIJ897\n",
      "T5M26AAA  TSM264\n",
      "D5HZ02TEA  TSN402\n",
      "TTC895GAA  TTC958\n",
      "80HVT4T59AA  UIV416\n",
      "Z1D562AAA  ZMW527\n",
      "153NDEAA  153NDE\n",
      "ABR53T0A  ABR5310\n",
      "CAB1069  CAB1069\n",
      "FHPA835AA  CRP836\n",
      "NA02641  NA02641\n",
      "NBC2309  NBC2309\n",
      "TNBF866Z  NBF8676\n",
      "NDT7127  NDT7127\n",
      "NE2G216AA  NE26216\n",
      "DJGGD5FE2EDDX  13360564601\n",
      "L1AE23T3A  ABE2313\n",
      "A8HFT5A4A  ABH1544\n",
      "NB15456  NBI5456\n",
      "N8T2564A  NBT2564\n",
      "NDT8216L  NDT8216\n",
      "NEBBZ74  NEB8274\n",
      "HEJ2518A  NEJ2572\n",
      "NFT6109AA  NFT6109\n",
      "M1FEBAAA  NHO560\n",
      "FGSS5GAA  PIO960\n",
      "HG5EN1T54  WIN754\n",
      "E5H505AA  XSY504\n",
      "GB011JLAA  401DJL\n",
      "LAD158652  ADA5892\n",
      "APA7080A  APA7080\n",
      "CDZ5495  CDZ5495\n",
      "DAL8625  DAL8625\n",
      "DR183AAA  DRL923\n",
      "MJZ1G8A  MJZ168\n",
      "NAT6342  NAT6342\n",
      "NCC1180  NCC1100\n",
      "NDC2372  NDC2372\n",
      "HEA661AA  NEA5661\n",
      "TTW8Z63AA  TYN763\n",
      "Z85U03A  ZKS104\n",
      "0AT1D52T53  0414052153\n",
      "510TPD  510TPD\n",
      "AAM4S0TA  AAM4901\n",
      "AAQ8870  AAQ8870\n",
      "TAXA3085  AXA3085\n",
      "DAA7239  DAA7239\n",
      "EDAG11P5D8A  DAG1195\n",
      "HDEFY86EAAA  DFY682\n",
      "BKKEE20A  DNV820\n",
      "V00P0TTAA  DPU714\n",
      "0Y0GA6AA  DVU496\n",
      "DWZ3B8  DWZ336\n",
      "NE1565  NBE1565\n",
      "NCH2661A  NCH2661\n",
      "NCT8802  NCT8802\n",
      "NGF4110  NGF4110\n",
      "NGS8307  NGS8307\n",
      "5EGF195AA  SLG365\n",
      "ENAA1A  WFN441\n",
      "HKY8Y86AA  WKY191\n",
      "C001Z5B8AA  WUQ758\n",
      "1E8D0E34E2A  13800893494\n",
      "S307PZAA  307PZA\n",
      "GAC1219  BAC1219\n",
      "HHPAEZ1AA  JFH823\n",
      "LZCLUVWLAAA  ZCV116\n",
      "B53DPQA  853DPQ\n",
      "A2Z021A  A2Z021\n",
      "AAJST81  AAJ9181\n",
      "GEM56AAA  CLM544\n",
      "BAT0757A  DA10791\n",
      "RDAA9889  DAA9889\n",
      "D1J3127A  DAJ3327\n",
      "DAT1060  DAT1060\n",
      "DG70T89AA  DC70119\n",
      "GCS7606A  GCS7606\n",
      "REH51WGAAA  JDS115\n",
      "ENAE1815  NAE1815\n",
      "HNAR3508E  NAR3508\n",
      "NAT1827  NAT1827\n",
      "NBA9743  NBA9743\n",
      "NCR8656  NCR8656\n",
      "NDA1963  NDA1693\n",
      "NEX7507  NEX7507\n",
      "NFY2439  NFY2439\n",
      "FNFY2439  NFY2439\n",
      "EEH8MT5AAA  PJO114\n",
      "PJX1SA  PJY785\n",
      "PST335FA  PST335\n",
      "TJP3G3A  TJP363\n",
      "TTNNSG2L  TNN962\n",
      "TYR689AA  TYR689\n",
      "DAR98EA  UAR946\n",
      "EGEZ2AA  UFG542\n",
      "KBH6YTAA  XBP611\n",
      "8TWUZ5F5A  XML355\n",
      "ABH883S  ABH8899\n",
      "AB07G568  ABQ7659\n",
      "ABQSG2S  ABQ9626\n",
      "AKAS280  AKA9280\n",
      "BEE5F95RE  BEB959\n",
      "DAH3342  DAH3342\n",
      "NAK44386A  NAK4386\n",
      "NCP1449  NCP1449\n",
      "4ZPYXG2EA  P7X662\n",
      "5TWT2AA  TIW342\n",
      "0EH505AA  UFH505\n",
      "UUPD5S3A  UPD333\n",
      "S8HTGT2AUA  URT124\n",
      "SHER5GCAAA  VEP568\n",
      "3M651G5E1A  WOG656\n",
      "GGEEHZ5AA  XGE143\n",
      "EYTA05AA  YT4054\n",
      "YZBV22A  YZ0422\n",
      "HF56GSJG5L  ZDP310\n",
      "Z635X3AAA  7635X\n",
      "AAY4074  AAY4074\n",
      "ATA3251  AIA3251\n",
      "DAC3453  DAC3413\n",
      "DAF4129A  DAF4129\n",
      "DA19086  DAI9086\n",
      "LDAJ4126L  DAJ4126\n",
      "EDGP9554F  DCP9554\n",
      "0YT33A  DYT333\n",
      "NBA7993  NBA7993\n",
      "NBV6196  NBV6196\n",
      "NCW7897  NCW7897\n",
      "WHGK9TGAA  WBK918\n",
      "WEU202AA  WLU208\n",
      "LAGAFG883  AGA6883\n",
      "TETGT3LA  AKA3673\n",
      "DA93GTSA  DA93819\n",
      "DBA1734A  DBA1734\n",
      "DCP1485  DCP1485\n",
      "CDE679AAA  DDL6798\n",
      "52HG3SAA  DXP298\n",
      "NGY2496  NGY2496\n",
      "HNHQT98FA  NI4709\n",
      "NN0LZ49AA  NNO149\n",
      "JTDD8GTAA  TDD861\n",
      "PU1Z5AA  UPQ257\n",
      "5G4GBAA  VFE488\n",
      "SECCFGAAA  ZEJ956\n",
      "DAC7436  DAC7436\n",
      "DAE1045  DAE1045\n",
      "PDL5262  DDL5848\n",
      "NE19103  NEI9103\n",
      "NFH9524T  NFW9824\n",
      "0H4GAA  UHW464\n",
      "0XGS85ZAAA  UKG657\n",
      "NAE2616  NAE2616\n",
      "UNDX8504  NDX8504\n",
      "RFH2T1A  RFH211\n",
      "EHEFFFCAA  SKE924\n",
      "SABE78GAAA  A6I276\n",
      "ABG5030  ABG5030\n",
      "LDAH4645  DAH4645\n",
      "UAC234  UAC234\n",
      "040TJ2JDG25  04011230625\n",
      "129DKTA  129DKT\n",
      "T30TEGT75T5T  13011131579\n",
      "EEECE2ZEZAA  13801213902\n",
      "153TZBAA  153TZB\n",
      "Z53ZMAAA  2536WS\n",
      "340PZKAA  340PZK\n",
      "415NG0AA  415NGO\n",
      "641T68XACAA  4168XC\n",
      "AAH60S88  AAH6098\n",
      "AA0T470  AAO1410\n",
      "DC154G3AA  ACA5463\n",
      "LAHA2225A  AHA2225\n",
      "APAGG72  APA6672\n",
      "YBFZ5395  BC49695\n",
      "R2H51457A  BDB459\n",
      "DAB1391  DAB1391\n",
      "DAL8038  DAL8038\n",
      "DAU1856  DAU1856\n",
      "EG12252  DBA3050\n",
      "DGG0873A  DC60873\n",
      "DDL9445A  DDL9445\n",
      "0ED25VA  DLD251\n",
      "BVZZ265GA  DVZ266\n",
      "0XN5BBA  DXN588\n",
      "YT326A  DXT326\n",
      "5QAT5HAA  GNA754\n",
      "JEV335AA  JEV333\n",
      "EZEV1EPAAA  LEN38\n",
      "NAB9128  NAB9128\n",
      "WAHZE0A  NAH7830\n",
      "N107522  NAO7522\n",
      "NAU4467  NAU4467\n",
      "S0PEEE9AA  NBD8009\n",
      "NCA1238  NCA1238\n",
      "NCB7161  NCB7161\n",
      "NCF5226Y  NCF5226\n",
      "F4NCN2B57F  NCN2857\n",
      "NCU9737A  NCU9737\n",
      "NDD7821  NDD7821\n",
      "NDR2268A  NDR2268\n",
      "NEA9103  NEA9103\n",
      "NED8751  NED8751\n",
      "NEF1096  NEF1096\n",
      "NF94380  NF94380\n",
      "NFX5179  NFX5179\n",
      "NG0S95ZA  NG15917\n",
      "PMAPTJ5SAA  PMU139\n",
      "PNATTTR23A  PNA113\n",
      "RDVSHA  RJV271\n",
      "WSSTY6EAAA  S1Y770\n",
      "0RRM1G5AAA  TIY659\n",
      "FTJS2845A  TJS294\n",
      "TKV3Z2A  TKV342\n",
      "TLEB98BAA  TLB988\n",
      "TEN8S0X4AA  TLN904\n",
      "TNY174A  TNV174\n",
      "TYG561A  TYG561\n",
      "EWZ05AA  UEM203\n",
      "WYSEMAAA  UIN920\n",
      "WY6V856AA  VDU856\n",
      "WPB34ZAA  WBP347\n",
      "KB6B8SAA  WBR894\n",
      "WUH654AAA  WQR544\n",
      "ET4HDAA  XT4712\n",
      "ERGEFAAA  ZEP890\n",
      "Z0E57GAA  ZHE708\n",
      "103\n",
      "308\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "real_images_val = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\valid\\\\*\\\\*.png')\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\marty\\\\*\\\\*.png')\n",
    "ctr = 0\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    image = cv2.imread(file).astype('float32')\n",
    "    test_image = cv2.resize(image,(94,24))/256\n",
    "    test_image = np.expand_dims(test_image,axis=0)\n",
    "    preds = model.predict(test_image) \n",
    "    decoded = tf.keras.backend.ctc_decode(preds,(24,))\n",
    "    text = \"\"\n",
    "    for i in np.array(decoded[0]).reshape(24):\n",
    "        if i >-1:\n",
    "            text += DECODE_DICT[i]\n",
    "    if label == text or label == text[1:] or label == text[:-1]:\n",
    "        ctr += 1\n",
    "    print(text,\" \"+ label)\n",
    "print(ctr)\n",
    "print(len(real_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_21744/3660101917.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  val_training_labels = np.array(val_labels)\n"
     ]
    }
   ],
   "source": [
    "val_training_set = np.array(val_data,dtype=np.float32)\n",
    "val_training_labels = np.array(val_labels)\n",
    "val_ragged = tf.ragged.constant(val_training_labels).to_tensor()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_training_set,val_ragged)).shuffle(640).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 24, 94, 3), (None, 12)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83a3ba54cbd1f7dfc2d1ef373eda2962c312d1019df78bd28c6b3b15cf8d1ffd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
