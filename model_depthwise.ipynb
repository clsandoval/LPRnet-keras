{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import keras.backend as K\n",
    "from generator import DataGenerator\n",
    "\n",
    "MODEL_NAME = \"depthwise_model_rabdomchars_perspective\"\n",
    "\n",
    "IMAGE_SHAPE = [94,24]\n",
    "CHARS = \"ABCDEFGHIJKLMNPQRSTUVWXYZ0123456789\" # exclude I, O\n",
    "CHARS_DICT = {char:i for i, char in enumerate(CHARS)}\n",
    "DECODE_DICT = {i:char for i, char in enumerate(CHARS)}\n",
    "NUM_CLASS = len(CHARS)+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    # Compute the training-time loss value\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class small_basic_block(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,out_channels,name=None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        out_div4=int(out_channels/4)\n",
    "        self.main_layers = [\n",
    "            keras.layers.SeparableConv2D(out_div4,(1,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_div4,(3,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_div4,(1,3),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.SeparableConv2D(out_channels,(1,1),padding='same',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "        ]  \n",
    "    \n",
    "    def call(self,input):\n",
    "        x = input\n",
    "        for layer in self.main_layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test this later\n",
    "\n",
    "class global_context(keras.layers.Layer):\n",
    "    def __init__(self,kernel_size,stride,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ksize = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def call(self, input):\n",
    "        x = input \n",
    "        avg_pool = keras.layers.AveragePooling2D(pool_size=self.ksize,strides=self.stride,padding='same')(x)\n",
    "        sq = keras.layers.Lambda(lambda x: tf.math.square(x))(avg_pool)\n",
    "        sqm = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x))(sq)\n",
    "        out = keras.layers.Lambda(lambda x: tf.math.divide(x[0], x[1]))([avg_pool , sqm])\n",
    "        #out = keras.layers.Lambda(lambda x: K.l2_normalize(x,axis=1))(avg_pool)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"kernel_size\": self.ksize,\n",
    "            \"stride\": self.stride,\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LPRnet(keras.Model):\n",
    "    def __init__(self, input_shape=(24,94,3), **kwargs):\n",
    "        super(LPRnet, self).__init__(**kwargs)\n",
    "        self.input_layer = keras.layers.Input(input_shape)\n",
    "        self.cnn_layers= [\n",
    "            keras.layers.SeparableConv2D(64,kernel_size = (3,3),strides=1,padding='same',name='main_conv1',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(name='BN1'),\n",
    "            keras.layers.ReLU(name='RELU1'),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,1),name='maxpool2d_1',padding='same'),\n",
    "            small_basic_block(128),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,2),name='maxpool2d_2',padding='same'),\n",
    "            small_basic_block(256),\n",
    "            small_basic_block(256),\n",
    "            keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,2),name='maxpool2d_3',padding='same'),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.SeparableConv2D(256,(4,1),strides=1,padding='same',name='main_conv2',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.SeparableConv2D(NUM_CLASS,(1,13),padding='same',name='main_conv3',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),  \n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "        ]\n",
    "        self.out_layers = [\n",
    "            keras.layers.SeparableConv2D(NUM_CLASS,kernel_size=(1,1),strides=(1,1),padding='same',name='conv_out',kernel_initializer=keras.initializers.glorot_uniform(),bias_initializer=keras.initializers.constant()),\n",
    "        ]\n",
    "        self.out = self.call(self.input_layer)\n",
    "\n",
    "    def call(self,inputs,training=False):\n",
    "        x = inputs\n",
    "        layer_outputs = []\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "            layer_outputs.append(x)\n",
    "        scale1 = global_context((1,4),(1,4))(layer_outputs[0])\n",
    "        scale2 = global_context((1,4),(1,4))(layer_outputs[4])\n",
    "        scale3 = global_context((1,2),(1,2))(layer_outputs[6])\n",
    "        scale5 = global_context((1,2),(1,2))(layer_outputs[7])\n",
    "        sq = keras.layers.Lambda(lambda x: tf.math.square(x))(x)\n",
    "        sqm = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x))(sq)\n",
    "        scale4 = keras.layers.Lambda(lambda x: tf.math.divide(x[0], x[1]))([x , sqm])\n",
    "        gc_concat = keras.layers.Lambda(lambda x: tf.concat([x[0], x[1], x[2], x[3], x[4]],3))([scale1, scale2, scale3, scale5,scale4])\n",
    "        for layer in self.out_layers:\n",
    "            gc_concat = layer(gc_concat)\n",
    "        logits = keras.layers.Lambda(lambda x: tf.math.reduce_mean(x[0],axis=1))([gc_concat])\n",
    "        logits = keras.layers.Softmax()(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_11472/2036217571.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training_labels = np.array(labels)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "\n",
    "real_images_val = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\valid\\\\*\\\\*.png')\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\marty\\\\*\\\\*.png')\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "val_data = []\n",
    "val_labels = []\n",
    "\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    label = label.replace(\"O\",\"0\")\n",
    "    image = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image,(94,24))/256\n",
    "    data.append(image)\n",
    "    labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "\n",
    "for file in real_images_val:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    label = label.replace(\"O\",\"0\")\n",
    "    image = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image,(94,24))\n",
    "    val_data.append(image)\n",
    "    val_labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "\n",
    "training_set = np.array(data,dtype=np.float32)\n",
    "training_labels = np.array(labels)\n",
    "ragged = tf.ragged.constant(training_labels).to_tensor()\n",
    "real_dataset = tf.data.Dataset.from_tensor_slices((training_set,ragged)).batch(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(MODEL_NAME):\n",
    "    model = keras.models.load_model(\n",
    "        MODEL_NAME, custom_objects={\"global_context\": global_context, \"CTCLoss\": CTCLoss  }\n",
    "    )\n",
    "else:\n",
    "    model = LPRnet()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),loss =CTCLoss)\n",
    "    model.build((1,24,94,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_11472/2355684483.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training_labels = np.array(gen_labels)\n"
     ]
    }
   ],
   "source": [
    "from gen_plates_keras import *\n",
    "gen = ImageGenerator()\n",
    "def generate_dataset(num = 100):\n",
    "    data, labels = gen.generate_images(num)\n",
    "    gen_labels = []\n",
    "    for label in labels:\n",
    "        gen_labels.append([CHARS_DICT[i] for i in label.split('_')[0]])\n",
    "    pics =np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    training_set = np.array(pics,dtype=np.float32)\n",
    "    training_labels = np.array(gen_labels)\n",
    "    ragged = tf.ragged.constant(training_labels).to_tensor()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((training_set,ragged)).shuffle(640).batch(64)\n",
    "    return dataset\n",
    "test_dataset = generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mclsandoval\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/clsandoval/depthwise_model_rabdomchars_perspective/runs/7onrx0x7\" target=\"_blank\">vague-armadillo-5</a></strong> to <a href=\"https://wandb.ai/clsandoval/depthwise_model_rabdomchars_perspective\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=MODEL_NAME, entity=\"clsandoval\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 400,\n",
    "  \"batch_size\": 64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = DataGenerator()\n",
    "check = tf.keras.callbacks.ModelCheckpoint(\n",
    "    './{}'.format(MODEL_NAME),\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=500,\n",
    "    options=None,\n",
    ")\n",
    "model.fit_generator(generator=generate,validation_data=real_dataset,validation_steps=5,epochs=10000,steps_per_epoch=50,callbacks=[WandbCallback(),check])\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as RELU1_layer_call_and_return_conditional_losses, RELU1_layer_call_fn, dropout_layer_call_and_return_conditional_losses, dropout_layer_call_fn, re_lu_12_layer_call_and_return_conditional_losses while saving (showing 5 of 85). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\carlos\\AppData\\Local\\Temp\\tmpew6g2xkf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\carlos\\AppData\\Local\\Temp\\tmpew6g2xkf\\assets\n",
      "WARNING:absl:Found untraced functions such as RELU1_layer_call_and_return_conditional_losses, RELU1_layer_call_fn, dropout_layer_call_and_return_conditional_losses, dropout_layer_call_fn, re_lu_12_layer_call_and_return_conditional_losses while saving (showing 5 of 85). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: depthwise_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: depthwise_model\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "model.save(MODEL_NAME)\n",
    "\n",
    "with open(\"{}.tflite\".format(MODEL_NAME), 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(\"keras_lprnet_vanilla.tflite\")\n",
    "import numpy as np\n",
    "import time \n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\marty\\\\*\\\\*.png')\n",
    "start = time.time()\n",
    "ctr = 0\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    image = cv2.imread(file)\n",
    "    test_image = cv2.resize(image,(94,24))/256\n",
    "    test_image = np.expand_dims(test_image,axis=0)\n",
    "    test_image = test_image.astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    decoded = keras.backend.ctc_decode(output_data,(24,),greedy=False)\n",
    "    text = \"\"\n",
    "    for i in np.array(decoded[0]).reshape(24):\n",
    "        if i >-1:\n",
    "            text += DECODE_DICT[i]\n",
    "    if label == text:\n",
    "        ctr += 1\n",
    "    print(text, \" \"+ label)\n",
    "print(time.time()-start)\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    MODEL_NAME, custom_objects={\"global_context\": global_context, \"CTCLoss\": CTCLoss  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAC158G  AAC1586\n",
      "A01JY0TS4A  040101007794\n",
      "QGLAW485T  04010464051\n",
      "450DLY  459DLY\n",
      "40LG1WMAA  4703LW\n",
      "5647WXAAA  5647WX\n",
      "VA105592L  AAO5592\n",
      "APA3772A  APA3772\n",
      "G0AA4626  DAA4626\n",
      "DAF9190  DAF9190\n",
      "DAJ1083  DAJ1083\n",
      "DAL3300A  DAL3300\n",
      "DCP7079  DCP7079\n",
      "0HK50AA  DWK95Q\n",
      "0XNG52A  DXN659\n",
      "NBU4828  NBU4828\n",
      "NCG1221  NCG1221\n",
      "NCH8029  NCH8029\n",
      "NCM9415  NCM9415\n",
      "NEH1815  NEH1815\n",
      "NFX7563  NFX7563\n",
      "NGS2592  NGS2592\n",
      "WUUPAF4AAA  VDU712\n",
      "VEC186ZA  VEC862\n",
      "ZAZ12Z0  ZAZ220\n",
      "ZFLA555A  ZFZ596\n",
      "FWV5ZTUAAA  ZMY321\n",
      "A0060G3  04010101065\n",
      "6FZF7MMDAAA  04011094993\n",
      "S8QFQ0A9D2A  18010044592\n",
      "AAJ5201A  AAJ5201\n",
      "AAP1274A  AAP1274\n",
      "AAW1583  AAW1583\n",
      "UABA8675  ABA8615\n",
      "AEA9483  AEA9483\n",
      "AEA9512A  AEA9512\n",
      "GARUGB28S  ARA6828\n",
      "HASA8G80  ASA8680\n",
      "TBGE247A  B6E247\n",
      "ECXQ6650  CAQ6650\n",
      "CPY779AA  CPY711\n",
      "0UG7486AA  DA57485\n",
      "DAG3746  DAG3746\n",
      "DAH3150  DAH3150\n",
      "DAK1304S  DAK1304\n",
      "DAL7407  DAL7407\n",
      "DA06200E  DAO6200\n",
      "WDAY1428A  DAY1428\n",
      "DCP5431  DCP5431\n",
      "DCP7323  DCP7323\n",
      "Q25B17Z2AA  DD66174\n",
      "0XX225A  DXX225\n",
      "0XY6TS8A  DXY758\n",
      "EBQ8QM9AA  E2O801\n",
      "Z5WTPC95AA  JAT99\n",
      "BKNBLHM9LAA  K1B519\n",
      "NA36503  NA36503\n",
      "NAE1322  NAE1322\n",
      "NAE2008  NAE2008\n",
      "WAJ874D  NAJ8740\n",
      "NBA4750  NBA4750\n",
      "NBK6857  NBK6857\n",
      "NBP3395  NBP3395\n",
      "NBR9407  NBR9407\n",
      "NC04583  NC04583\n",
      "NCD4761  NCD4761\n",
      "GNCM8042  NCM8042\n",
      "NCM9147  NCM9147\n",
      "NDE9713  NDE9713\n",
      "NDF2712  NDF2712\n",
      "NDJ3111A  NDJ3111\n",
      "NDS1024  NDS1024\n",
      "LN0T140  NDV1148\n",
      "NEA4294  NEA4294\n",
      "NED230A  NED2300\n",
      "NED3275  NED3275\n",
      "LNEH44B2  NEH4482\n",
      "GNGJ4631  NGJ4631\n",
      "FP61E1B2G6A  P1E482\n",
      "9PJY2285  P3Y226\n",
      "R02GGGA  RD2666\n",
      "TAJB00AA  TAJ800\n",
      "ST1JX891TB  TIJ897\n",
      "T5M26AA  TSM264\n",
      "05N402LA  TSN402\n",
      "TTC6958AA  TTC958\n",
      "U0YVX4T6AA  UIV416\n",
      "ECC5ZTAA  ZMW527\n",
      "153NDEAA  153NDE\n",
      "ABR53T0A  ABR5310\n",
      "CAB1069  CAB1069\n",
      "CRFA836A  CRP836\n",
      "NA02641  NA02641\n",
      "NBC2309  NBC2309\n",
      "NBF8676L  NBF8676\n",
      "NDT7127  NDT7127\n",
      "NE2G216A  NE26216\n",
      "D3J60515QDL  13360564601\n",
      "EA8E13T3AA  ABE2313\n",
      "ABHT5A1A  ABH1544\n",
      "NBT5456  NBI5456\n",
      "N8T2564  NBT2564\n",
      "NDT8216  NDT8216\n",
      "NE88Z74  NEB8274\n",
      "C2J5LAA  NEJ2572\n",
      "NFT6109EA  NFT6109\n",
      "AGCS15GJAA  NHO560\n",
      "KKSS6UZA  PIO960\n",
      "W1N1T54  WIN754\n",
      "X5V4504A  XSY504\n",
      "4B0A10JLA  401DJL\n",
      "A0A5882  ADA5892\n",
      "APA7080A  APA7080\n",
      "CDZ5495  CDZ5495\n",
      "DAL8625  DAL8625\n",
      "DRL5Z3AAA  DRL923\n",
      "M5Z168  MJZ168\n",
      "NAT6342  NAT6342\n",
      "NCC1100  NCC1100\n",
      "NDC2372  NDC2372\n",
      "MEA5661T  NEA5661\n",
      "CTN663A  TYN763\n",
      "Z51UU5A  ZKS104\n",
      "0A18D52758  0414052153\n",
      "510TPDA  510TPD\n",
      "AAM4S0TA  AAM4901\n",
      "AAQ8870A  AAQ8870\n",
      "AXA3085  AXA3085\n",
      "DAA7239  DAA7239\n",
      "K0LG195YA  DAG1195\n",
      "0EYG68RA  DFY682\n",
      "BKW6BZ0A  DNV820\n",
      "00P0TTAA  DPU714\n",
      "0YUGA6GA  DVU496\n",
      "DNZ8BGA  DWZ336\n",
      "NBE1565  NBE1565\n",
      "NCH2661  NCH2661\n",
      "NCT8802  NCT8802\n",
      "NGF4110  NGF4110\n",
      "NGS8307  NGS8307\n",
      "5E0XJ0JAA  SLG365\n",
      "QNFNAA1P  WFN441\n",
      "MRY8T61A  WKY191\n",
      "L00175BA  WUQ758\n",
      "1J80G8Q9135QA1  13800893494\n",
      "N307PZAA  307PZA\n",
      "B1C1219A  BAC1219\n",
      "JTH8Z3LA  JFH823\n",
      "4CV4ULAAA  ZCV116\n",
      "853DPQA  853DPQ\n",
      "A2Z021AA  A2Z021\n",
      "AAJ9781A  AAJ9181\n",
      "CEM56AA  CLM544\n",
      "8AT0791AA  DA10791\n",
      "5D4A988Q  DAA9889\n",
      "DAJ3327A  DAJ3327\n",
      "DAT1060  DAT1060\n",
      "DC70119A  DC70119\n",
      "GCS7606  GCS7606\n",
      "J05XTTGAAA  JDS115\n",
      "ANAE1815  NAE1815\n",
      "NAR3508  NAR3508\n",
      "NAT1827  NAT1827\n",
      "NBA9743A  NBA9743\n",
      "NCR8656  NCR8656\n",
      "NDA1963A  NDA1693\n",
      "NEX7507  NEX7507\n",
      "NFY2439  NFY2439\n",
      "NFY2439  NFY2439\n",
      "ES0ATT4AAA  PJO114\n",
      "PJY18SAA  PJY785\n",
      "PST3356  PST335\n",
      "TJP3G3A  TJP363\n",
      "TNNSG2  TNN962\n",
      "TYR689AA  TYR689\n",
      "DXB8UEA  UAR946\n",
      "UEGFLTEAA  UFG542\n",
      "SBP6V1AA  XBP611\n",
      "ATVX365F5AA  XML355\n",
      "ABH8869  ABH8899\n",
      "AB07G59A  ABQ7659\n",
      "AB09G2GA  ABQ9626\n",
      "AKA9280  AKA9280\n",
      "BEBA95F  BEB959\n",
      "DAH3342  DAH3342\n",
      "NAK4386A  NAK4386\n",
      "NCP1449  NCP1449\n",
      "FPHXG82EAA  P7X662\n",
      "FTDWA34ZAA  TIW342\n",
      "0EH505A  UFH505\n",
      "UPD333A  UPD333\n",
      "W8HTGT24ALW  URT124\n",
      "VEP568  VEP568\n",
      "DW0GA6564  WOG656\n",
      "QLP84TFA  XGE143\n",
      "PYT4054A  YT4054\n",
      "MZB422A  YZ0422\n",
      "5Z0P83T0L  ZDP310\n",
      "7655XXAA  7635X\n",
      "AAY4074  AAY4074\n",
      "ATA3251  AIA3251\n",
      "DAC3413  DAC3413\n",
      "DAF4129E  DAF4129\n",
      "DAT9086  DAI9086\n",
      "DAJ4126  DAJ4126\n",
      "DCP9554F  DCP9554\n",
      "DYT33A  DYT333\n",
      "NBA7993  NBA7993\n",
      "NBV6196  NBV6196\n",
      "NCW7897  NCW7897\n",
      "NBK69TBAA  WBK918\n",
      "MEUZ08A  WLU208\n",
      "AGAA6883  AGA6883\n",
      "K13G63A  AKA3673\n",
      "DAS38T9A  DA93819\n",
      "DBA1734  DBA1734\n",
      "BCP1485  DCP1485\n",
      "DL6798A  DDL6798\n",
      "63X546XSA  DXP298\n",
      "NGY2496  NGY2496\n",
      "1NM1TQ9PA  NI4709\n",
      "NN0LT6A94AA  NNO149\n",
      "ETDD8G1A  TDD861\n",
      "0P01Z5A  UPQ257\n",
      "LKE488A  VFE488\n",
      "4FS15SRA  ZEJ956\n",
      "DAC7436  DAC7436\n",
      "04E1045  DAE1045\n",
      "C0L5848  DDL5848\n",
      "NET9103  NEI9103\n",
      "NFW9824L  NFW9824\n",
      "Z0HWMF668A  UHW464\n",
      "04K9SSZA  UKG657\n",
      "NAE2616  NAE2616\n",
      "NDX8504  NDX8504\n",
      "RFH21TA  RFH211\n",
      "EEELDEGA  SKE924\n",
      "FA6TC78GAA  A6I276\n",
      "ABG5030A  ABG5030\n",
      "DAH4645  DAH4645\n",
      "0AC234  UAC234\n",
      "8401J123J0G25  04011230625\n",
      "126DKY  129DKT\n",
      "J0M7J75T  13011131579\n",
      "1BT7H3BJ21  13801213902\n",
      "153TZBA  153TZB\n",
      "Z53V5AA  2536WS\n",
      "340PZKAA  340PZK\n",
      "415NG0AA  415NGO\n",
      "41T6GXGA  4168XC\n",
      "AAHG0S8  AAH6098\n",
      "AA01470  AAO1410\n",
      "EC54G3A  ACA5463\n",
      "RAA2226A  AHA2225\n",
      "AP1GG72  APA6672\n",
      "M0E4S695  BC49695\n",
      "B0BA459AA  BDB459\n",
      "DAB1391  DAB1391\n",
      "DAL8038  DAL8038\n",
      "DAU1856  DAU1856\n",
      "KUU3050  DBA3050\n",
      "FGG0873AA  DC60873\n",
      "00L9445  DDL9445\n",
      "0E0Z5UAA  DLD251\n",
      "RVZLZ65A  DVZ266\n",
      "0XN588A  DXN588\n",
      "0XT3Z6A  DXT326\n",
      "B0A75BAAA  GNA754\n",
      "JEV333AA  JEV333\n",
      "E4JLJVA  LEN38\n",
      "NAB9128  NAB9128\n",
      "3TH7830A  NAH7830\n",
      "KA07522  NAO7522\n",
      "NAU4467  NAU4467\n",
      "FQ0B092A  NBD8009\n",
      "NCA1238  NCA1238\n",
      "NCB7161  NCB7161\n",
      "NCF5226  NCF5226\n",
      "NCN28574  NCN2857\n",
      "NCU9737  NCU9737\n",
      "NDD7821  NDD7821\n",
      "ND0R2268A  NDR2268\n",
      "NEA9103  NEA9103\n",
      "NED8751  NED8751\n",
      "NEF1096A  NEF1096\n",
      "NF94380  NF94380\n",
      "NFX5179  NFX5179\n",
      "NGT59T7  NG15917\n",
      "PM0U319AA  PMU139\n",
      "PNATT3AA  PNA113\n",
      "NJVENAA  RJV271\n",
      "FESYTH0SAA  S1Y770\n",
      "TY1G5DA  TIY659\n",
      "ETJS284F  TJS294\n",
      "TKV342AA  TKV342\n",
      "TLB988A  TLB988\n",
      "TENS08AA  TLN904\n",
      "TNY174A  TNV174\n",
      "TYG561A  TYG561\n",
      "0EMX203A  UEM203\n",
      "UVWKSE0A  UIN920\n",
      "NVUU856  VDU856\n",
      "WPB34ZAA  WBP347\n",
      "MCR8S4AA  WBR894\n",
      "WUH1544A  WQR544\n",
      "FET4TJ1JAA  XT4712\n",
      "ZEP8S0A  ZEP890\n",
      "GZHE170BA  ZHE708\n",
      "87\n",
      "308\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "real_images_val = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\valid\\\\*\\\\*.png')\n",
    "real_images = glob.glob('C:\\\\Users\\\\carlos\\\\Desktop\\\\cs\\\\ml-sandbox\\\\ANPR\\\\LPRnet-keras\\\\test\\\\marty\\\\*\\\\*.png')\n",
    "ctr = 0\n",
    "for file in real_images:\n",
    "    label = file.split('\\\\')[-1].split('_')[0].split('-')[0]\n",
    "    image = cv2.imread(file).astype('float32')\n",
    "    test_image = cv2.resize(image,(94,24))/256\n",
    "    test_image = np.expand_dims(test_image,axis=0)\n",
    "    preds = model.predict(test_image) \n",
    "    decoded = tf.keras.backend.ctc_decode(preds,(24,))\n",
    "    text = \"\"\n",
    "    for i in np.array(decoded[0]).reshape(24):\n",
    "        if i >-1:\n",
    "            text += DECODE_DICT[i]\n",
    "    if label == text:\n",
    "        ctr += 1\n",
    "    print(text,\" \"+ label)\n",
    "print(ctr)\n",
    "print(len(real_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlos\\AppData\\Local\\Temp/ipykernel_21744/3660101917.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  val_training_labels = np.array(val_labels)\n"
     ]
    }
   ],
   "source": [
    "val_training_set = np.array(val_data,dtype=np.float32)\n",
    "val_training_labels = np.array(val_labels)\n",
    "val_ragged = tf.ragged.constant(val_training_labels).to_tensor()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_training_set,val_ragged)).shuffle(640).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 24, 94, 3), (None, 12)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83a3ba54cbd1f7dfc2d1ef373eda2962c312d1019df78bd28c6b3b15cf8d1ffd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
